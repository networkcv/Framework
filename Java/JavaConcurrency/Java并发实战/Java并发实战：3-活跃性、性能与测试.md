# 10.避免活跃性问题

## 10.1 死锁

## 10.2 死锁的避免和诊断

## 10.3 其他活跃性危险

# 11.性能与可伸缩性

多线程的主要目的还是提高程序的运行性能，使程序更加充分地发挥多核CPU的高性能，提高系统的资源利用率，此外线程还可以使程序在运行现有任务的情况下立即处理新任务，从而提高系统的响应性。

在保证线程安全性的前提下，将性能提升至最大。

## 11.1 对性能的思考

提升性能意味着用最少的资源做更多的事情。对于一个给定的操作，通常会缺乏某种特定的资源，例如CPU的时钟周期、内存、网络带宽、I/O带宽、数据库请求、磁盘空间以及其他资源，当操作性能由于某种特定的资源而受到限制时，我们通常将该操作称为资源密集型的操作，例如：CPU密集型、数据库密集型、I/O密集型，了解这一点，才能更好的根据硬件设备来确定创建线程的数量，一般情况下，随着线程数的增加，吞吐量会增加，延迟也会缓慢增加；但当线程增加到一定程度，吞吐量反而会下降，延迟会迅速增加，这个时候基本就是线程设置的最大值了。

CPU密集型：CPU核数+1

I/O密集型：CPU核数×[ 1 + (I/O耗时 / CPU耗时)]

尽管多线程的目的是提升性能，但是使用多个线程会引入额外的性能开销。如：线程之间的协调（加锁、触发信号、内存同步等），增加的上下文切换，线程的创建和销毁，以及线程的调度等。如果过度地使用线程，那么这些开销将超过性能的提升，使得并行程序比串行程序的性能还要差一些。

### 11.1.1 性能与可伸缩性

应用程序的性能可以采用多个指标来衡量,例如服务时间、延迟时间、吞吐率、效率、可伸缩性以及容量等。其中一些指标(服务时间、等待时间)用于衡量程序的“运行速度”，即某个指定的任务单元需要“多快”才能处理完成。另一些指标(生产量、吞吐量)用于程序的 “处理能力”,即在计算资源一定的情况下,能完成“多少”工作。

可伸领性指的是,当增加计算资源时(例如CPU、内存、存储容量或I/O带宽),程序的吞吐量或者处理能力能相应地增加。

性能的两个方面“多快”和“多少”，是完全独立的，有时候甚至是相互矛盾的，对于服务器而言“多少”（可伸缩性、吞吐量和生产量）比“多快”这个方面更重要一些。

### 11.1.2 评估各种性能权衡因素

“快速排序”算法在大规模数据中的执行效率非常高，但对于小规模的数据来说，“冒泡排序”实际更高效。程序的优化需要根据真实的场景来制定，所以，为了避免不成熟的优化，先让程序正常运行，然后在提高速度。

空间换时间，安全换性能。

## 11.2 Amdahl定律

## 11.3 线程引入的开销

### 11.3.1 上下文切换

可运行的线程数大于CPU数量，那么操作系统会将某个正在执行的线程调度出来，从而使其他线程能够使用CPU，这将导致一次上下文切换，在这个过程中将保存当前运行线程的执行上下文，并将新调度进来的线程的执行上下文设置为当前上下文。

当线程由于等待某个发生竞争的锁而被阻塞时，JVM通常会将这个线程挂起，并允许它被调度出去，程序中发生的阻塞（包括阻塞I/O、等待获取发生竞争的锁、或者在条件变量上等待）越多，CPU密集型的程序发生的上下文切换也就越多，从而增加调度开销，降低了系统的吞吐量。

上下文切换的开销会随平台不同而变化，大多数通用的处理器中，上下文切换的开箱相当于5000～10000个时钟周期。

### 11.3.2 内存同步

之前提到volatile和synchronized的可见性保证会使用一些特殊指令，即内存栅栏，内存栅栏可以刷新缓存，使缓存无效。还会禁止一些编译器优化操作，在内存栅栏中，大多数操作都是不能被重排序的。

### 11.3.3 阻塞

锁竞争失败会阻塞，JVM在实现阻塞行为的时候，可以通过自旋锁的方式（不把线程挂起，通过不断循环尝试获取锁，直到成功）或者通过操作系统挂起被阻塞的线程。这两种方式的效率高下，取决于上下文的开销和成功获取锁前需要等待的时间，如果等待时间小于上下文切换的时间开销(5k~10k个时钟周期)，则适合采用自旋的方式，反之，则适合采用挂起的方式。有些JVM会根据历史等待时间的数据分析在两者之间选择，大多数JVM在等待锁时都只是将线程挂起。

当线程无法获取某个锁或者是由于某个条件等待或是I/O操作上阻塞时，需要被挂起，在这个过程中将包含两次额外的上下文切换，以及必要的操作系统操作和缓存操作。

## 11.4 减少锁竞争

串行操作会降低可伸缩性，并且上下文切换会降低性能。在锁上发生竞争将同时导致这两种问题，因此减少锁的竞争能够提高性能和可伸缩性。

影响锁上发生竞争的两个可能性：

- 锁的请求频率

- 每次持有该锁的时间

有三种方式可以降低锁的竞争程度，允许更高的并发性：

- 减少锁的持有时间
- 降低锁的请求频率
- 使用带有协调机制的独占锁

### -11.4.1 缩小锁的范围（快进快出）

降低发生竞争可能性的一种有效方式就是尽可能缩短锁的持有时间。例如,可以将一些与锁无关的代码移出同步代码块,尤其是那些开销较大的操作,以及可能被阻塞的操作,例如1/ 0操作。

我们都知道,如果将一个“高度竞争”的锁持有过长的时间,那么会限制可伸缩性,例如在第2章中介绍的SynchronizedFactorizer的示例。如果某个操作持有锁的时间超过2毫秒并且所有操作都需要这个锁,那么无论拥有多少个空闲处理器,吞吐量也不会超过每秒500个操作。如果将这个锁的持有时间降为1毫秒,那么能够将这个锁对应的吞吐量提高到每秒1000个操作。

程序清单11-4给出了一个示例,其中锁被持有过长的时间。userLocationMatches方法在一个Map对象中查找用户的位置,并使用正则表达式进行匹配以判断结果值是否匹配所提供的模式。整个userLocationMatches方法都使用了synchronized来修饰,但只有Map.get这个方法才

### 11.4.2 减小锁的粒度

### 11.4.3 锁分段

### 11.4.4 避免热点域

### 11.4.5 一些替代独占锁的方法

### 11.4.6 监测CPU的利用率

### 11.4.7 向对象池说不

## 11.5 比较Map的性能

## 11.6 减少上下文切换的开销

## 小结



#  12.并发程序的测试

## 12.1 正确性的测试

## 12.2 性能测试

## 12.3 避免性能测试的陷阱

## 12.4 其他的测试方法