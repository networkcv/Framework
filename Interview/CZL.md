# string 

Redis的字符串数据结构为  动态字符串 (Dynamic Simple String) ，内部实现类似ArrayList，采用预分配冗余空间的方式减少内存分配。

大小小于 1M时 加倍扩容 大于1M时则每次扩容增加1M 

字符串长度最大512M

数据结构：

```
{
T capacity; 容量
T len;    长度
byte flags;  特殊标志位
byte[] content; 字节数组
}
```

为什么要使用泛型？ 字符串小的时候 这两者可以用short和byte表示。极致优化。

每个RedisObject都有一个对象头

{

int4 type  // 4bit    数据结构类型 

int4 encoding  //4bit   数据结构类型的不同存储方式

int24 lru      // 24bit   LRU信息

int32 refcount   //4bytes   引用计数

void *ptr;      //8bytes 64-bit system  数据内容的地址

}

字符串有两种存储方式。一种是embStr 一种是raw。取决于字符串内容长度是否大于44bytes。

embstr的结构是将对象头与对象体连续存在一起，这样只会分配一次内存。相对于raw减少了一次内存分配。极致优化。

# hash

底层的数据机构为 数组+链表  与Java的HashMap一致

## 字典Dict的数据结构：

字典内部保存了两个HashTable   用于渐进式rehash。 

单个HashTable的结构为数组+链表。

## 渐进式Rehash

Hash在很大的时候，rehash的资源开销比较大。Redis为了不阻塞服务，采用了渐进式rehash。

渐进式rehash是指 ： 当在rehash时，会保留新旧两个hash结构，同时查询两个hash结构，并在后续的定时任务和hash指令中慢慢的迁移至新的hash结构中。

hdel hget等指令会触发 rehash迁移，还有定时任务也可以触发。

## 扩容和缩容

当元素达到数组长度时会扩容，按一倍扩。 

如果在bgsave的时候，则会等到五倍数组长度才扩容。

缩容条件为元素条件只有数组长度的10%。



# List

## 底层数据结构

Redis中的列表实际上是一个双向链表。

## ZipList

当列表的元素较少时，会采用ZipList这种数据结构，否则使用QuickList。

ZipList数据结构

int32 zlbytes //整个压缩链表大小

int32 zltail_offset  //最后一个元素距离列表起始位置的偏移量，用于快速定位最后一个元素，实现双向遍历

int16 zllength  //元素个数

T[] enties   // 元素数组

int8 zlend     //标志压缩列表结束 值恒定为0xFF。

元素的数据结构中保存了 前一个元素的大小 ，用于遍历。

### ZipList的增加、修改、删除

因为压缩列表没有冗余的空间，因此针对压缩列表的元素的 增加、修改、删除操作会引起列表的级联更新。

## QuickList

quickList 实际上是zipList和linkedList的组合。 因为链表的附加空间占用太高，因此quickList对列表进行分段。

每段列表实际上是LinkedList，使用指针项链。

而每个LinkedList中的数据使用ZipList使其紧凑。



# Zset

ZSet中可以存储 Value，Score。

内部会根据Score来对Value进行排序。

## 底层数据结构

ZSet为有序Set集合。 是由两种数据结构复合而成。 是由Hash结构与SkipList结构组合。

## SkipList

在跳跃表中，每个值都有层数，可以比作一幢高楼。

根据Score定位一个元素：

如下图，从Head开始（该Head无值），从第一层开始向下查找是否是最后一个大于当前值的节点，若查到了则向下一层继续查，最终查到底层，则定位成功。

**个人理解：（实际上就是用层数对值进行分割，层数越高，值相差越大。实际上是减少遍历次数）。**

Redis默认是64层高。

对于一个新的元素，它的层数由随机函数决定，从第一层往上，概率为50%Level1 25%Level2 以此类推。

若从64层开始查询则太慢，因此会记录当前最高层数，提高性能。


# 分布式锁
## 原理  

### 获取锁
setnx命令   【当Key不存在的时候才会设置成功】  
若返回成功则相当于拿到了锁。  

##### 若拿到锁的线程一直不释放怎么办？
setnx命令提供了 ex参数可以原子的设置过期时间。避免线程一直持有锁不释放。  

但这无法解决业务逻辑超时的问题。因此不要把Redis锁用于时间过长的业务逻辑。必要时人工介入。


##### 如何确保不会被别的线程解锁？
set一个随机数，当随机数匹配的时候才能够解锁。这时就要使用Lua脚本执行。保证原子性。



##### 可重入
本系统中没有设计可重入的分布式锁。会增加复杂度，在代码结构层面屏蔽使用可重入的分布式锁。

# Redis持久化
#### RDB模式【存储快照】
因为Redis是单线程的，所以不能阻塞主进程响应客户端，因此Redis会fork（派生）一个子线程来进行快照复制。

快照RDB文件是以二进制形式紧凑存储在磁盘上的。  

> ##### 若在存储快照的时候数据发生变更，如何解决并发问题？
> 操作系统的CopyOnWrite技术。当子进程被fork的时候，子进程与父进程共享同一个内存空间。父进程在写内存的时候操作系统复制一份数据段出来然后再复制出来的这段数据上修改。    
> 
>**解决了什么问题？**
>
>大大减少fork子进程时的性能开销。同时保证快照为fork那刻的数据。
>
>**还有什么问题？**
>
>没有增量数据。此时要配合使用AOF模式。


#### AOF模式
该模式会将Redis执行的命令一一保存到文件里。  
> **原理**
> 当Redis接收到一条写命令时，会将该命令执行后追加到AOF文件中【**注意此时还在内存中**】。  
> 然后调用 **fsync** 命令将其写入磁盘。  
> 一般该命令配置为1s一次





#### Redis宕机恢复
Redis在宕机或者重启的时候，需要加载原有的内存数据结构。  

此时可以使用RDB快照文件加载。【**但这种方式没有最新数据**】

也可以使用AOF文件重放命令加载。【**该种方式效率低**】

**通常采用混合模式**
Redis4.0提供了混合持久化，该种持久化会将RDB文件与该快照之后的AOF增量文件存在一起。加载的时候会很快。


# 过期策略
Redis中所有的数据结构都可以设置过期时间。


过期时间是针对Key的。


### 定时遍历
Redis会将设置了过期时间的Key放入一个独立的字典中。然后定时启动任务来删除过期的Key。

过期扫描不会扫描所有的Key。采用的是一种简单的贪心策略。
1）从过期字典中随机选出20个Key
2）删除这20个Key中过期的Key
3）如果过期的比例超过25%  就重复执行步骤1

Redis还设置了扫描时间上限  25ms。避免出现过度循环。


### 惰性删除
除了定时任务以外。Redis还会在访问某一个Key的时候判断该Key是否过期。若过期则删除并返回nil。


### 内存使用策略
当Redis的内存使用超出物理内存限制的时候，Redis会使用几种淘汰策略来进行Key的淘汰来腾空内存。

1）noeviction: 不再提供写入的方法。
2）volatile-lru: 淘汰设置了过期时间的Key，最少使用的优先淘汰。
3）volatile-ttl: 淘汰设置了过期时间的Key,ttl小优先被淘汰
4) volatile-random: 同上，淘汰过期Key中随机的Key
5）allkeys-lru: 在所有的Key中，优先淘汰最少使用的Key
6）allkeys-random：在所有Key中，随机淘汰Key.


### LRU算法实现
```
class LRUCache {

    private Map<Integer,CacheItem> map;
    private int size = 0;

    private final CacheItem head = new CacheItem(0,0);
    private final CacheItem tail = new CacheItem(0,0);

    public LRUCache(int capacity) {
        this.size = capacity;
        map = new HashMap<>(size);
        //初始化链表
        head.next = tail;
        tail.pre = head;
    }
    
    public int get(int key) {
        if (!map.containsKey(key)) {
            return -1;
        }
        CacheItem cache = map.get(key);
        //将该值移动到头部
        moveCacheToHead(cache);
        return cache.value;
    }
    
    public void put(int key, int value) {
        //若存在 则覆盖 不删除值
        if (map.containsKey(key)) {
            CacheItem cache = map.get(key);
            cache.value = value;
            //将当前值移动到头部
            moveCacheToHead(cache);
        }else{
        //若不存在  则判断是否还有空间
            if(map.size() == size){
                //移除尾部元素
                CacheItem removed = removeTail();
                //同时删除Map中的值
                map.remove(removed.key);
            }
            //写入
            CacheItem cache = new CacheItem(key,value);
            map.put(key,cache);
            addToHead(cache);
        }
    }

    private void moveCacheToHead(CacheItem cache){
        CacheItem pre = cache.pre;
        CacheItem next = cache.next;
        if(pre == head){
            //已经在头部了 则不动
            return;
        }
        //先将当前点摘出来
        pre.next = next;
        next.pre = pre;
        //然后将当前点放入头部
        addToHead(cache);
    }

    private void addToHead(CacheItem cache){
        CacheItem currentHead = head.next;
        head.next = cache;
        cache.pre = head;
        cache.next = currentHead;
        currentHead.pre = cache;
    }



    private CacheItem removeTail(){
        CacheItem target = tail.pre;
        CacheItem pre = target.pre;
        pre.next = tail;
        tail.pre = pre;
        return target;
    }


    private static class CacheItem{

        int key;
        int value;

        CacheItem pre;
        CacheItem next;

        public CacheItem(int key,int value){
            this.key = key;
            this.value = value;
            this.pre = null;
            this.next = null;
        }

    }
}

/**
 * Your LRUCache object will be instantiated and called as such:
 * LRUCache obj = new LRUCache(capacity);
 * int param_1 = obj.get(key);
 * obj.put(key,value);
 */
```

# Redis 集群高可用
### 分布式CAP理论

> C   Consistent 一致性
> A   Availability  可用性
> P   Partition tolerance  分区容忍性
>
> CAP理论就是  当网络分区发生时，一致性和可用性难以兼顾


#### Redis 集群

简介： Redis是CA集群，当网络分区发生时，Redis仍旧可以提供服务。Redis并不满足一致性。而满足最终一致性。


#### Redis 主从同步

Redis主节点和从节点采用的是异步同步数据的方式。主节点会将修改指令保存至本地buffer，然后异步将指令同步给从节点。从节点执行指令同时反馈偏移量（执行到哪里了）。    主节点的本地buffer是环状结构，后面的指令会覆盖前面的指令。   若从节点没有跟上主节点，则会使用快照同步。



#### Redis Sentinel

>Redis Sentinel 哨兵集群。  由若干个节点组成，节点负责监控Redis集群的运行状态。客户端需要从Sentinel中获取主节点的地址来进行连接操作。
>
>当出现Redis主节点宕机时，Sentinel会监控到系统异常，然后从从节点中选举出一个主节点来恢复集群。


#### Sentinel 如何确认master宕机
> 当哨兵A发现主节点宕机之后，会发布主观宕机消息。同时询问其他哨兵，当指定数量的哨兵【通常配置为半数以上，避免发生脑裂】都认为宕机了则认定为客观宕机。
> 
> 哨兵们会选举出一个leader来执行主从切换过程。

##### 如何选举

采用Raft协议来选举出来一个Leader


##### 如何切换

Sentinel向被选中的Redis节点发送slaveof no one命令来让其升级为Master节点。




#### Redis Cluster

Redis官方提供的一种去中心化集群策略。  Redis Cluster这种集群模式下，可以存在多个主节点，每个主节点之间平等。

Redis Cluster 将数据分为16384个分片。它们成称为slot。这些slot被分布在各个节点上。当写入Key的时候

# ES
#### 什么是ES？
用于全文检索的全文搜索引擎。底层采用的是开源的Lucene。Es对Lucene进行了封装。提供REST接口进行查询。


#### Lucene



#### DSL
查询语句
```
GET 索引名/_search
{
    //查询
   "query":{
        "term":{
            "fieldName":""
        }
   }
}
```
> term 精确查询
> terms 匹配多个的精确查询 相当于SQL里的in


# Pulsar 笔记
### 简介
Pulsar是一个 高性能 服务器到服务器的消息中间件。

Pulsar特性：
* Pulsar的单个实例原生支持多个集群，可跨机房在集群间进行消息复制。
* 极低的发布延迟和端到端延迟
* 支持  独占订阅、共享订阅、故障转移订阅
* 通过 Apache BookKeeper 提供的消息持久化机制保证消息传递。
* 基于 Pulsar Functions 的 serverless connector 框架 Pulsar IO 使得数据更易移入、移出 Apache Pulsar。
* 分层式存储可在数据陈旧时，将数据从热存储卸载至冷存储。


### Pulsar组件简介

#### Message 消息
> 消息是Pulsar的基础单元。  
> 每条消息都有一个  序列号，该序列号在Topic中代表了消息的顺序。


#### Producer 生产者
> **访问模式**：
> * Shared 多个生产者可以发布消息至同一个Topic
> * Exclusive  只有一个生产者能发送到这个Topic，其他生产者若发送则会报错。

> **批处理**：
> 当批处理启用时，生产者能够组合一批消息作为一个消息单元【其中会有多个消息】，而消费者也是按单元消费消息。以单元维度来确认消息。
> 可以利用该特性作原子性操作。

> **分块**：
> 目前不知道用处


#### Consumer 消费者
> **订阅模式**
> 单一订阅、共享订阅
> **消息确认**
> 单条确认、批量确认【只需要确认最后一条即可】
> **取消确认**
> 消费者能够对某一条消息重新消费
> **确认超时**
> 客户端会跟踪超时时间范围内的未确认消息，然后发送重亲确认请求至Broker
> **死信队列**
> 未被成功消费的消息可以被投递至该队列。
> **重试**
> 配置生产者投递消息到业务Topic与重试Topic。若客户端消费失败，则客户端会自动冲重试队列中消费消息。


#### Topic 
> **持久化、非持久化**
> 能够配置是否持久化
> **租户**
> Pulsar能够在租户层面对Topic进行隔离
> 租户可以分布在集群中
> **命名空间**
> 将Topic分组
> 租户 > 命名空间 > Topic


#### 订阅
* **独占**
> 只有一个Consumer能够连接同一个订阅
* **共享**
> 多个Consumer能够同时连接订阅，通过轮流的方式分发给Consumer。确保一个消息只有一个Consumer消费。
* **灾备**
> 多个Consumer能够同时连接订阅，但只有一个消费者能够消费。发生网络分区时，未被确认的消息会被发送至下一个Consumer
* **Key共享**
> 多个Consumer能够同时连接订阅，消息中对于同一个Key的消息总会被同一个Consumer消费
> ![f45f85791c34a7f1e2244c8f67a45d5a.png](evernotecid://DF9753E5-AF7B-4019-BD9E-6F56A94D7C9A/appyinxiangcom/40219267/ENResource/p1)

#### 分区Topic
Pulsar 可以显示创建分区Topic  一个Topic在内部被分为几个分区（Partition）。每个分区可能被不同的Broker处理。以增加吞吐量。

* **路由模式**
> 路由模式代表Producer该发往哪一个分区。
> * RoundRobinPartition
> 该模式为默认模式：若消息指定Key，则会根据Key的hash值分配到指定分区。若不指定Key，则以round-robin方式发送到所有分区。
> * SinglePartition
> 若指定Key，则根据Key的hash值分配到指定分区。若不指定，则生产者随机选择一个分区，然后发送所有消息至这个分区。

#### 消息顺序保证

> 对于有Key的消息，单个Key都是有序的，因为它们会被分配到同一个Partition

> 对于无Key的消息，若路由策略为SinglePartition，则同一个生产者的消息是有序的。

#### Pulsar 如何保证消息不丢失

> 首先当收到Send Ack的时候  我们就认为消息已经投递成功了。剩下的由Pulsar来保证消息的持久化。
>
> 而如何保证我们的消息一定投递成功的。  目前我们的工程是接入了任务引擎。来实现最终一致性。  所有的消息发送全部都走的引擎。  由引擎来确保消息一定投递成功。



#### Pulsar 消息的有序性。

> 首先Pulsar本身保证同一个Topic里面  同样Key的消息天然有序。

> 在生产的时候   还需要在消息设计上对全局顺序有顺。我们目前是采用DB版本号和更新时间戳。以DB的更新时间戳为准。 按该时间戳把消息发出去。


#### Pulsar 采集Binlog的有序性保证

> BinLog采集这个场景中。   会出现顺序问题。  BinLog必须要按顺序消费。
> 目前的架构中，是一张表一个Topic来采集BinLog
> 在Pulsar中 KeyShard订阅模式下  支持同一个Key只有一个Consumer消费。所以对于单个表来说以Id作为Key 能够保证顺序消费。

**问题： 如果多个Topic存在顺序依赖问题呢？ 比如多表变更事务。然后事务间存在依赖。 如何解决？待考证**



# ThreadLocal

####  简介
ThreadLocal该类用于操作和自定义线程私有变量。


####  ThreadLocalMap
每个Thread对象中都有一个ThreadLocalMap实例，该实例本质上是一个HashMap，
存储的是   ThreadLocal  --> Value的映射

ThreadLocal类本质上就是操作这个线程上的ThreadLocalMap实例。

ThreadLocalMap本质是一个基于数组的HashMap,但是它没有用链表来解决Hash冲突。
```
Hash冲突的时候  本质上没有解决Hash冲突
1. 得到Key的HashCode
2. 数组长度取余得到下标i
3. 若该点已经有值且不为当前Key，则i+1 循环 直到找到空的下标或者本身为止
```


#### ThreadLocalMap的Entry是使用的弱引用 为什么？

> 因为 ThreadLocalMap被Thread线程持有，若Thread一直存活则ThreadLocalMap也会存活。  若此时ThreadLocalMap中的ThreadLocal这个Key已经被回收了，但ThreadLocalMap中的Entry就无法被回收了。  因此Entry继承弱引用，使得ThreadLocal被回收后  ThreadLocalMap中的Entry也能正常被回收。

# AQS
#### 简介
抽象的基于队列的同步器。  该抽象类是JUC包中同步工具的基类。
下面都以ReentrantLock为例。

### 详细
> AQS中存在一个 CLH锁定队列的变体，CLH通常用于自旋锁，但Dung Lea将其用于阻塞同步器。

> 维护一个Head节点与Tail节点，这两个节点不是虚节点 也是实际存储线程的节点。入队只需要操作Tail节点  出队只需要操作Head节点。

> 使用一个state来维护锁状态。

#### 获取锁【非公平】

> 1. 尝试调用CAS更改AQS锁状态。 若更改成功则获得锁。并将当前线程设置为获取锁的线程。若获取失败则进行锁的争夺。
> 2. 调用AQS的acquire方法来争抢锁。  首先会进行一次tryAcquire尝试获取，成功则成功获取锁。失败则进入队列自旋。
> 3. AQS会调用addWorker将该节点加入队列尾部，尝试加入【使用CAS更改队列Tail的引用】，失败则循环。
> 4. 当加入队列成功后，开始处理当前线程状态。
>    若当前线程在队列头部，那么尝试获取锁。成功后返回。
>    若线程不在头部或者获取锁失败，则判断是否应该PARK来减少CPU小号。
>    **队列   HEAD->N1->N2->N3-N4-TAIL  若HEAD正在使用锁，则只有N1是自旋获取锁，后续的全部阻塞**


#### 释放【非公平】

> 1. 解锁的时候只需要简单对比线程是否一致以及重入次数是否一致即可解锁。无须CAS。同时释放的时候不会通知。由头部节点自行保证。

# 线程池
## 简介
因为线程是一种非常宝贵的资源，它的创建与销毁是非常消耗资源。因此线程池用于池化线程。提高性能。在Java中  是ThreadPoolExecutor类


#### 核心参数
* corePoolSize  核心线程数。
* maxPoolSize   最大线程数。
* keepAliveTime  空闲线程存活时间
* timeUnit      时间单位
* workQueue      工作队列   阻塞队列，任务会放到这个队列里面。
* threadFactory    线程工厂，控制线程池中的线程的创建
* rejectedExecutionHandler  拒绝策略



#### 参数定义
##### 线程数
对于IO密集型任务。适当调大线程数。
对于计算密集型任务，则将CPU核心线程数作为核心线程数。以发挥最大性能。

##### 存活时间
按需选择

##### 工作队列
最好不要采用无界队列。  使用有界队列来进行限制，增加系统容错性。

##### 线程工厂
最好是自己构建，标记线程的名称，在Debug的时候会方便。  同时还有一些 包装Runnable的情况。  比如异步执行的时候 需要将上下文传递进去。

#### 拒绝策略|
当工作队列满时会触发拒绝策略。
* **AbortPolicy 【默认策略】**   提交任务时直接抛出异常
* CallerRunPolicy  由提交者线程来完成任务
* DiscardOldestPolicy 丢弃最早的未处理的任务
* DiscardPolicy  丢弃当前提交的任务



### 线程池 任务生命周期

当调用线程池的submit方法时，内部会将Runnable包装称为一个RunnableFuture由该类控制任务生命周期。异常则被包掉。在Future中取得

而线程池的execute方法则不会包装。所以当抛出异常时，会触发UncaughtException。线程池默认输出至System.err     需要在ThreadFactory中设置线程的UncaughtExceptionHandler。


### 线程池的监控、动态调整

可以自己继承ThreadPoolExecutor  来重写部分方法 例如beforeExecute  afterExecute等方法实现对线程池的监控。


同时线程池提供了 setCoreSize等方法来动态更改线程池参数。

# Synchronized
## 简介

该关键字是由 Jvm实现的一种同步器。 被synchronized关键字修饰的临界区代码，同一时间只会有一个线程能够执行。


#### 修饰

* 修饰在普通方法上：   锁当前对象实例
* 修饰在静态方法上：   锁当前对象的Class对象
* 修饰在代码块上：     锁入参的对象。

#### 特性
* 可重入
* 锁粗化
* 锁升级
* 由Jvm保证自动解锁


#### 原理【这里MarkWord就不多讲了】

> 在编译的时候，编译器会在临界区代码头部和尾部插入monitor enter 和monitor exit指令。这两个指令分别对应着获取锁和解锁。

#### 锁升级

> **取得锁**
> 锁的信息都在被锁对象的对象头MarkWord里。  取得锁的本质就是将当前线程的信息使用CAS写入到这个MarkWord里。
> 此时涉及到锁的升级。
> **无锁-> 偏向锁** 得到锁时会先升级为偏向锁。此时锁会一直偏向正在执行的线程
> **偏向锁-> 轻量级锁** 当偏向锁存在竞争时，则会升级为轻量级锁，为得到锁的线程会自旋去获取锁。
> **轻量级锁-> 重量级锁** 当轻量级锁的竞争非常激烈，或者自旋锁自旋次数过多，则会升级为重量级锁。 未得到锁的线程则进入队列阻塞等待。



#### 锁粗化
当出现synchronized嵌套的时候，Jvm会自动将锁的范围变大。这就是锁粗化。
# volatile

#### 特性
* 禁止指令重排序
* JMM模型下线程间的可见性保证



#### 禁止指令重排

JVM在对代码优化的时候，会针对不违反happend-before原则的代码进行指令重排。也就是说没有相关性的代码，它们的顺序可能与编写顺序不一致。   使用了volatile之后，关于该变量的任何操作都不能进行指令重排。



#### 可见性保证

被volatile修饰的变量。在线程对该变量进行写的时候，会强制的将该变量写回主内存。同时使所有线程中的该变量副本失效。


# JVM

### 类加载过程

* 加载
> 通过一个全限定类名来加载一个类文件的二进制流。可以任意位置【比如从Zip压缩包中获取，从网络上获取，从DB中获取，运行时生成等等】
* 验证
> 验证该字节码文件是否是符合规范的类文件。
* 准备
> Jvm会在这个阶段进行类变量初始值的分配。【注意是类变量  而不是实例变量】
* 解析
> 在这个阶段 Jvm会将类的常量池中的符号引用替换为直接引用。比如说由符号引用直接指向一个Method对象。
* 初始化
> Jvm会执行 类变量和静态代码块的赋值操作。 


### 类加载器
通过类加载器来加载一个类。

**特性：**
> 对于任意一个类，只有加载它的类加载器和类本身才能在Jvm中确定一个唯一性。若一个类由不同类加载器加载，则它们也是不同的类。


在Java中存在三类类加载器
* **Bootstrap ClassLoader 【启动类加载器】**
> 在HotSpot中由C++实现，用于加载rt.jar等核心包中的类。
* **Extension ClassLoader 【扩展类加载器】**
> 由Java实现，用于加载Java系统的扩展类。
* **Application ClassLoader 【应用程序类加载器】**
> 负责加载用户类路径下的所有类。如果应用中没有自定义过类加载器。则都使用该加载器加载。 


### 双亲委派模型
在该模型下，当一个类加载器收到类加载请求时，不会直接加载它，而是委托给父类加载器去加载。父类加载器也会执行相同策略。最终由启动类加载器去加载。
只有当顶层加载器无法加载时【抛出ClassNotFound】才会向下透传直到有一个加载器能加载为止。

##### 为什么要使用双亲委派模型？
> **保证类唯一性的语义。**
> 同时确保核心类的安全性。不会出现重复字节码。


##### 破坏双亲委派模型
在该模型下，越基础的类越由上层加载器加载。但也会出现基础类调用用户类的情况出现。例如JNDI服务。该服务需要调用各个厂商编写的SPI代码。但是启动类必然无法加载这些代码。

另外还有OSGi实现热部署，热加载。直接替换掉类加载器来实现。

### JMM内存模型简介
这个应该被称为Java多线程内存模型。Java定义内存模型来屏蔽不同操作系统、不同架构的物理机中的内存访问差异。使得上层对内存的访问总是一致的。


### JVM内存分布
Jvm在启动的时候，会向操作系统申请一块内存用于当前Jvm进程使用。  该内存在Jvm中被分为几块区域。
* 堆（Heap）【几乎所有的对象都在这里分配内存】【线程共享】
* 堆-方法区（Method Area）【线程共享】
* 程序计数器【线程不共享】
* 虚拟机栈【线程不共享】
* 本地方法栈【线程不共享】


#### 内存区分
在Java线程内存模型中，内存被分为两部分。
* 主内存
> 所有的数据均存储在主内存中。【该内存实际为虚拟机内存的一部分】
* 线程私有内存
> 该部分内存线程私有。


#### 共享变量与线程

![be08b5ed57ed9d5cbb175ac646c83a5c.png](evernotecid://DF9753E5-AF7B-4019-BD9E-6F56A94D7C9A/appyinxiangcom/40219267/ENResource/p2)

> 当线程需要一个共享变量时，会由JMM控制去主内存中【堆内存】取得该共享变量的副本并存储在线程本地。之后的执行均在线程本地对这个变量副本进行操作。

> 因此不同线程之间的相同共享变量是屏蔽不可见的。这也是多线程开发需要注意的。


#### Java 数据原子操作指令
简介：主内存与工作内存之间的数据交互规范。JMM定义了8中原子操作。这些操作是抽象的，由Jvm来实现。 


* read【读取】从主内存读取数据
* load【载入】将主内存读取到的数据写入工作内存
* use【使用】从工作内存中读取数据进行计算
* assign【赋值】将计算好的值重新赋值到工作内存中
* store【存储】将工作内存数据写入主内存
* write【写入】将store过去的数据赋值给主内存中的变量
* lock【锁定】将主内存变量加锁，标记为线程独占
* unlock【解锁】将主内存变量解锁

**注** 后续已经将描述简化为read、write、lock、unlock四种。但实际操作没有简化。

#### 线程工作内存是什么？
这个很重要。我们这里讲的线程工作内存。实际上就是CPU的寄存器和高速缓存的抽象。


#### Volatile语义
##### 内存可见性
在JMM中，Volatile需要保证 被Volatile修饰的对象，当它被写回主内存时，其他线程中的数据副本均无效化。
##### 内存可见性的实现
* 字节码层面
> 被volatile修饰的变量 在字节码层面会被标记为一个Volatile对象
* JVM层面
> 在HotSpot实现中，对一个volatile变量的写入，在翻译为汇编语言时。如下
* 汇编语言层面
```
以上省略
> moveb  $0x0,0x1104800(%esi)     该语句为赋值语句
> lock addl $0x0,(%esp)     执行一个lock指令
```
> **lock** 指令介绍：
> 当执行该指令时，会锁总线，独享共享内存，会将本处理器的缓存写回内存。又因为MESI协议的保证，其他处理器也会无效化该变量的缓存。相当于一个内存屏障。

#### 指令重排序
指令重排序分为三种
##### 源代码层面重排序
编译器在不影响单线程顺序语义的情况下，可以重新安排语句的执行顺序。
**对于该种重排序  JMM重排序规则会禁止特定类型的编译器重排序**
##### 指令集重排序和内存重排序
CPU层面，现代处理器采用指令集并行处理技术，如果不存在数据依赖可以将指令发送到不同的处理单元进行处理。

CPU层面，现代处理器的内存系统重排序。由于CPU使用高速缓存和读写缓冲区，使得加载和写
入操作看起来是乱序的。

**对于CPU层面的重排序，JMM在生成指令序列的时候会插入内存屏障来保证CPU级别的重排序**

##### heppends-before原则  volatile指令重排序。



#### MESI 缓存一致性协议   CPU硬件实现


##### 总线嗅探机制



### 讲下JMM


### JVM内存结构
* 程序计数器【线程私有】
> 用于记录程序执行的行数
* 虚拟机栈【线程私有】
> 用于执行Java方法的栈
* 本地方法栈【线程私有】
> 用于执行本地native方法栈
* 堆内存（Heap）【线程共享】
> 几乎所有的对象实例都在这里分配内存
* 方法区【线程共享】
> 存储类信息、常量、静态变量、即时编译器生成的代码等。


### GC 垃圾回收

#### 哪些对象需要回收
* 引用计数器
> 优点： 效率高
> 缺点： 单纯的引用计数器无法解决循环依赖问题。若要解决则可以使用强弱引用。出现循环引用的时候标记其中一个为弱引用。但这样会引入野指针问题。
* 可达性分析
> 基于GC ROOT这些节点向下发现引用链，在这些链外的对象均为需要回收的对象。
> GC ROOT： 虚拟机栈使用的对象、常量、静态变量、本地方法栈引用的对象等等。

##### 可达性分析
* 根节点枚举  【枚举GC ROOTS】
> 枚举所有的GC ROOTS。 这段时间需要冻结用户线程。需要在一致性的情况下得到这些枚举。  采用安全域实现。 同时JVM使用一种数据结构叫做OopMaps【从非收集区域指向收集区域的指针集合】来快速找到GC ROOTS。
* 标记 【追踪引用链】
> 然后进行引用链获取的时候，JVM在对象引用图中使用三色标记来进行标记。
> * 白色：没被收集器扫描的对象
> * 黑色：被扫描，已经扫描完全部引用。认为是存活的
> * 灰色：被扫描，但没有扫描完毕。
> **如何解决并发？** 请看QA

### 内存逃逸分析
当对象在方法中或者在线程中分配。然后返回透出给其他线程或者方法。就会造成对象逃逸。因为Jvm中对象的创建和销毁还是比较消耗性能的。如果对象没有逃逸的话。那么就可以在栈中分配内存并且跟随栈帧的销毁而回收。增加性能。




##### 引用
* 强引用
* 软引用
* 弱引用
* 虚引用

### 分代收集



### 垃圾回收算法
##### 标记复制
##### 标记清除
##### 标记整理





### 垃圾收集器
#### Serial
* 单线程
#### ParNew
* 多线程并行收集  仅收集阶段多线程
#### CMS【运行与老年代】
* 实现用户线程与GC线程并发执行
> 过程为  初始标记-》并发标记-》重新标记-》并发清除
> **缺点** 降低吞吐量、无法处理浮动垃圾【即并发情况下产生的垃圾】，浮动垃圾过多出现并发失败时则会STW并启用Serial Old来收集。而且CMS基于标记清除算法会产生空间碎片。

#### Parallel Scavenge
#### Serial Old
#### Parallel Old
### G1收集器
简介： 对于老的收集器来说，总是针对与一个分代进行收集，要么Minor GC、Major GC、Full GC。
而G1收集器则可以面向Heap 任意部分来组成回收集。
> 将连续的Java Heap 分割成不同的Region。每个Region可以是新生代、老年代。G1可以根据Region类型来使用不同的收集方式。
> 收集方式：
> * 初始标记 **STW**
> 标记GC ROOTS能直接关联的对象。开销很小
> * 并发标记 
> 开始并发执行可达性分析，并发问题采用初始快照解决。
> * 最终标记 **STW**
> 对并发标记的遗漏部分进行标记
> * 筛选回收 **STW**
> 计算统计数据，根据用户配置的GC参数选择合适的回收方案。涉及到对象的移动。


### JVM相关问题
**跨代引用如何解决？**
A: JVM使用 记忆集【非收集区域指向收集区域的指针集合】来解决。该问题发生在可达性分析根节点枚举时。

**JVM并发标记垃圾对象有什么问题如何解决？**
A: 并发标记时会出现两种情况，一种是对象意外存活。第二种是该存活的对象消失。
   为了解决对象消失问题。有两种方案
   * 增量更新
   > 黑色对象一旦插入一个白色对象的引用，就将其标记为灰色
   * 原始快照
   > 先对原始快照进行扫描，并发过程中产生的问题对象则在扫描完成后重新扫描一遍。

**G1收集器有什么优点？**
A: 能够对收集时间进行预测。能够设置GC参数。例如停顿时间。

### 来讲一下 JVM GC

# SpringBoot
### SpringBoot 启动流程


* new SpringBootApplication
1. 从META-INF/spring.factories配置文件中读取
   ApplicationContextInitializer、ApplicationListener
   并注册。
> ApplicationContextInitializer
> 用于在refresh之前初始化上下文。

> ApplicationListener
> 用于SpringBoot启动监听。 监听容器启动的各个阶段事件。

* run()
1. 配置enviroment环境。然后绑定到当前SpringApplication。**注意不是ApplicationContext**
2. 实例化ApplicationContext容器。
3. prepareContext
4. refreshContext
5. afterRefresh
6. 启动成功后  调用所有的ApplicationRunner


#### prepareContext 【装载所有的BeanDefinition】
> 在此阶段的几个重要节点
> **1. postProcessApplicationContext**
> 应用ApplicationContext的后处理器。例如BeanNameGenerator。
> **2. applyApplicaitonInitialier**
> 应用ApplicationContext初始化器。
> **3. 开始装载所有的BeanDefinition**
> 通过Source源装载所有BeanDefinition。SpringBoot工程默认从主方法的类开始。


#### refreshContext
> 在此阶段的几个重要节点
> **1. prepareBeanFactory**
> 对BeanFactory进行配置。




## Bean的生命周期

#### 实例化前处理
#### 实例化
#### 实例化后处理
#### 





Bean 工厂实现应尽可能支持标准的 Bean 生命周期接口。 全套初始化方法及其标准顺序是：


BeanNameAware 的setBeanName
BeanClassLoaderAware 的setBeanClassLoader
BeanFactoryAware 的setBeanFactory
EnvironmentAware 的setEnvironment
EmbeddedValueResolverAware 的setEmbeddedValueResolver
ResourceLoaderAware 的setResourceLoader （仅在应用程序上下文中运行时适用）
ApplicationEventPublisherAware 的setApplicationEventPublisher （仅在应用程序上下文中运行时适用）
MessageSourceAware 的setMessageSource （仅在应用程序上下文中运行时适用）
ApplicationContextAware 的setApplicationContext （仅在应用程序上下文中运行时适用）
ServletContextAware 的setServletContext （仅在 web 应用上下文中运行时适用）
BeanPostProcessors 的postProcessBeforeInitialization方法
InitializingBean 的afterPropertiesSet
自定义初始化方法定义
BeanPostProcessors 的postProcessAfterInitialization方法
在关闭 bean 工厂时，以下生命周期方法适用：

# TCP
### Http Https协议
1. 文本协议
2. Http1.1后有长链接，可以一个连接处理多个请求，只不过是串行。有头部阻塞问题。


### Http2协议
1. http2协议上最小的通信单元为帧，每一个消息【理解为一个请求的完整包】由一个或多个帧组成。
2. 流式传输
3. 二进制协议
4. 真正实现多路复用，同一个Tcp连接并行而不是串行。
5. 头部压缩   服务器客户端会缓存消息头。


### Tcp 
1. 粘包拆包  这个问题发生在tcp协议和上层协议之间的交互。本质上是因为tcp是流式传输和操作系统的发送接收缓冲区导致。
2. 三次握手。    一次握手单方面会有问题，二次握手的话有一个端无法确认接收能力。
3. 四次挥手。    两次挥手的话只是确认了C/S不能发而已仍能接收数据。所以用四次挥手。
4. 顺序保证。  TCP协议的数据包都分配了序列号用于排序。




### Udp


# 项目
#### 商户重写
##### 背景
* 相似功能的接口多。
* 存在很多目前已经不用的业务逻辑。
* 因历史代码包袱导致不方便扩展。   具体可以Audit表举例。
* 部分接口性能存在问题。
* 可以平滑过渡。


##### 方案
于是我们采用了重写商户工程的方案。
> **Q：为什么要用重写，而不是在原有基础上重构？**
> 
>1. 第一点是原先的接口设计不合理。我们需要设计新的接口。那么基于这一点来说。新工程与老工程其实没有区别。
>2. 老工程中的历史包袱非常多，动起来牵扯很大。重构的成本很高。因此我们的方案是在保证数据模型不变的情况下依照现有业务逻辑来写。







### 项目流程
**1. 调研**
> 我们花了两到三周时间调研 外域目前依赖的接口。确定接口入参与接口含义以及接口返回值。
> 找产品以及外域产品开会对齐目前商户的业务模型与目前的业务逻辑。然后开会确定该种模型没有问题。
> 开始设计技术方案。

**2. 技术方案**
> 1. 首先新启两个工程 ypsx-owl、ypsx-phoenix 一个工程是用于中台管理端，一个工程是用于为外域提供原子服务。然后两个工程同时能够操作DB和Redis。且共享。
> 
> >**Q: 为什么是两个工程共享DB和Redis而不是一个工程访问另一个工程？**
> > 
> >通常对外服务不需要频繁发布。管理端在发布上不影响核心服务。
> >即使管理端出现异常挂掉了也不会影响核心服务。

> 2. 域内开发沟通过之后定义所有的接口。然后将接口文档通知外域。此时已经可以开始开发了。若出现接口不满足则根据调用场景与接口含义。判断是否在业务逻辑上做改造还是接口新增或改造。
> 3. 首先进行接口切换。phoenix工程与owl工程可以并行进行开发。phoenix工程开发对外接口，优先上线一部分核心接口可以让外域先切换。当对外服务稳定后，将会逐步的对老工程接口进行限流。同时大力推进接口的切换。
> 4. 切换的差不多了则考虑将老工程接口下线。基础架构组有接口调用监控。
> 5. 表结构变动
> > 管理端先使用双写操作。然后对外查询服务慢慢开始改造。

#### 项目细节
* **缓存设计**
> 缓存是提高性能的核心所在。但也会引入一些问题。比如缓存一致性问题。在缓存这块，我们核心方针是直接缓存PO，关联关系则使用HASH来缓存。缓存过期时间根据实体的访问量来定义。  为了预防缓存雪崩，实际上在使用时会根据定义的基准时间前后摆动随机摆动20%。
> 确保缓存一致性则使用延迟双删策略。在事务提交的时候会删除缓存，然后采集BinLog延迟几秒钟来删除缓存。
* **ES查询**
* **DB设计**
> 根据不同的业务实体分表操作。关联关系根据配送关系、销售关系分为两张表。里面根据类型区分不同实体的关系。 组织架构关系就直接写在实体表里了。
* **接口设计**
> 根据Id查询实体基础信息接口。带上类型。
> 根据Id查询实体详细信息接口。带上类型。
> 关联关系查询。会有状态入参。
> **Q : 如何实现不带类型的查询呢？**
> 因为以前的Id是单表生成。所以目前的数据切换仍然需要不同实体Id不一样。目前采用的是先在那张单表生成Id  然后写入类型表。查的时候通过这张表查Id。  然后这张表被永久缓存。


#### 项目中遇到的问题以及如何解决
* **Q：如何确保消息一定发出去了呢？**
> 我们引入了别的团队开发的分布式任务引擎来解决最终一致性问题。若消息发送失败则会对方法进行重试来确保最终一致性。TODO 怎么使用。


* **Q：BinLog采集的消息顺序性问题如何解决？**
> 对于目前的顺序问题我们是这么解决的。   首先我们基础架构组对于BinLog采集是一张表对应一个Topic。对于实体表，我们认为只要确保同一个Id的顺序性就可以。
> 基于Pulsar的特性。同一个分区内的消息总是FIFO的。首先在生产消息的时候，把实体Id作为Key。这样Pulsar总会把相同的Key路由到同一个分区中。对于同一个Id总是有序的。  
> 然后看消费端。消费者采用KeyShard模式。多个Consumer订阅的情况下，同一个Key的消息总会发送到同一个Consumer上。于是顺序消费可以保证。
> 对于关联关系表。我们目前只同步了组织架构关系。是1：1的关系，因此可以用一个实体Id来唯一确定一个Key。也能确保关系。


### 秒杀场景

1. 活动开始和结束标记。 这个标记一定是在内存中，可通过消息来触发或者定时任务修改之。
2. 过滤阶段。可根据业务设置过滤。 例如在秒杀场景中可采用随机过滤法。
--- 扣库存阶段
3. redis可预热一个库存值。 当减少为0时则秒杀结束。 库存非准确。
    1. redis的性能峰值。 使用阿里云20W QPS
    2. redis扛不住怎么办。
4. redis扣减成功后发送消息。 异步真正扣库存。
--- 生成订单阶段
5. 生成订单。返回。

# 分布式事务
### 二阶段提交【基于DB事务】
> 引入一个协调者。由协调者发起一次事务。
> 协调者会先会发送准备命令。 同时写一份Prepare Log
> 参与者执行本地事务，但不提交。并告知协调者执行结果。
> 协调者发现均通过则发送Commit命令。若不通过则发送失败命令。事务回滚。
> 参与者接收Commit命令提交事务。

有几个点：
**若一阶段超时，则协调者会有超时机制来发送事务回滚命令。**
**2PC是同步阻塞协议。只要有一个流程没有没返回执行结果。后续流程都不会执行。因此无法应对大并发场景**
**二阶段只能不断重试**

存在问题：
1. 因同步阻塞无法应对大并发场景
2. 存在单点故障问题。





### 三阶段提交协议【基于DB事务】
主要是为了解决2PC提交阶段，协调者与参与者挂掉的情况下导致的各个参与者状态不一致的问题。


引入预提交  介于准备阶段和提交阶段。具体如下。
> 协调者开启事务后，首先对所有参与者进行事务准备。例如事务能否执行等等。
> 当校验通过时，则会正式开始2PC的这种提交。

引入了参与者超时机制。参与者超时之后会根据自身状态来确认事务是否提交。

存在问题：
1. 同步阻塞无法应对大并发场景
2. 单点故障问题


### TCC 【业务实现】
引入事务管理器。由事务管理器来维护事务状态。对于事务的每一个流程节点来说，都需要写三个方法。try-confirm-cancel。  资源预留-提交-取消。

存在问题：
1. 单点故障
2. 业务侵入
3. 代码复杂

### 本地消息表

## 幂等
1. 重放问题。  采用数据库唯一键解决。   唯一键可以外部发号生成。
2. ABA问题。  采用版本号解决。  每次更新版本号+1，更新时的版本号由外部传入。


## 分布式事务
### 2PC
协调者、参与者。
性能差：因为在事务期间会锁定事务资源，如果出现宕机，则会一直占用资源。
单点故障：协调者故障就只能锁定资源。只有协调者有超时。
### 3PC

### TCC

### 本地消息表

### Seata阿里开源






# IO模型
## IO多路复用
[参考视频](https://www.bilibili.com/video/BV1Xt4y1U7zt?p=2)
https://www.bilibili.com/video/BV1JU4y1h7YM?p=10
#### 阻塞IO、非阻塞IO、IO多路复用模型
> **阻塞IO模型**
>
>     
>     应用程序需要读写数据时要进行系统调用，以recvfrom指令举例。在默认情况下，该指令的系统调用直到内核态数据报准备好且被复制至用户态或者错误才会返回。整个调用期间都是阻塞的。

​    

>
> **非阻塞IO模型**
>     
>     应用程序在调用recvfrom指令时，若内核态的数据报未准备好则直接返回EWOULDBLOCK错误。若已准备好，则开始复制至用户态然后返回。【通常用作轮询】


> **IO多路复用**
> 
>     在Linux中，操作系统提供了select/poll指令，传入一个或多个fd【文件句柄】，它会顺序扫描传入的fd是否就绪。该方法阻塞，直到返回一个或多个就绪句柄。


#### epoll指令优势？
> **epoll指令单个进程打开的fd仅受限于操作系统最大fd**
> 
>     因此能够支持上万连接。
> 
> **epoll指令不会轮询所有的fd，而是只操作活跃的fd**
> 
> **epoll通过用户内存mmap与内核同一块内存空间实现减少fd消息的内存复制**


#### IO多路复用  Java NIO
> **Selector【多路复用器】**
>    
>     Channel将注册在多路复用器上。多路复用器会在线程内调用select()方法获取是否有就绪的Channel，该方法阻塞直到有就绪的通道位置。然后调用selectedKeys()方法拿到通道集合。
>     select()方法底层是基于操作系统的命令。JDK1.8是基于epoll实现。


#### epoll简介
待写。



#### MMAP 写
> 是由操作系统提供的一项技术。将磁盘文件直接映射到用户内存中。有操作系统来保证磁盘的回写。减少了一次内核态到用户态的数据拷贝。


#### 零拷贝、DMA技术 读
> 在Linux服务器中。系统提供了sendfile指令。该指令会使用硬件提供的DMA技术，将文件拷贝到内核态内存空间，然后发送到socket缓冲区。不经过用户态。



### 讲一下IO模型与多路复用技术
在CS架构下。  传统阻塞IO，当客户端连接服务器的时候，服务器通常会分配一个线程去处理这个Socket的IO操作。  但是这样会浪费大量线程资源。 于是提出使用线程池来处理客户端IO，但是这样也没有提高吞吐量，线程仍然会阻塞在等待客户端IO上。**本质是因为操作系统的IO模型是阻塞的，以Linux为例，会阻塞在recv系统调用上，很难解决C10K问题**

于是Linux内核后来出现了NIO（non-block IO）。连接和读取均不会阻塞。理论上可以一个线程处理连接和数据处理。

于是就出现了一个线程循环遍历所有的客户端Socket，调用recv方法探测IO准备，若有IO则进行后续处理。但是这样会出现很多无效扫描，浪费CPU资源。于是操作系统又进行升级。


操作系统提供了select方法，可以告诉你Socket状态，然后再根据状态进行recv读取。这样就不会有很多无效扫描了。


于是多路复用技术就出现了。大量客户端Socket被注册到同一个多路复用器上，这个多路复用器会一直调用select方法得到Socket的IO状态，然后进行后续的IO处理。

**以上均为同步模型  只要是应用程序主动调用recv与操作系统进行IO数据交互均为同步模型**

但是又有弊端出现了。select本身性能不高。传入大量fd会造成用户态内核态的内存拷贝浪费资源。


# MySQL 
### 语句执行过程
连接器--> 查询缓存--> 分析器[词法分析]--> 优化器[查询优化,选择索引]--> 执行器 
--> 存储引擎（innoDB）


### 索引
数据表都是以主键顺序索引来存放的。
在InnoDB引擎中索引使用的是B+树模型。
#### B+ 树
平衡N叉树，N代表树的阶数。且所有的叶子节点均在同一层。仅叶子节点保存数据。
查询效率近似二分查询。更稳定
#### 提升查询效率
* **覆盖索引**
> 当需要查询的数据索引已经包含了。则被称为覆盖索引，减少一次回表操作。
* **索引下推**
> 在组合索引查询中，如果查询条件在索引中的话，则会优先根据索引过滤减少回表次数。
* **最左前缀原则**
> 自己知道即可



#### Join查询
* 方式一：当被驱动表上存在索引时 (Index Nested-Loop Join)
> 执行顺序为，从表A读入一行数据，然后通过索引去表B查询，然后拼接遍历返回。
> 
* 方式二：当被驱动表上没有索引时 (Block Nested-Loop Join)
> 将表1全部读到join buffer中，然后表2一行一行的读出来比对。


#### 数据库死锁排查与案例
商家入驻接口。
现场：线上出现大量接口超时。
排查：首先ECS的负载并不高，然后流量也不是很大。DBA那边说有大量的慢SQL日志。初步判断是DB的问题。  然后发现这些慢SQL理论上都是不慢的，考虑到是否是行被锁住了或者表被锁住了。查看事务，发现大量事务在等待表锁。且从执行的SQL上可以大致分辨出是入驻那一块。同时查了Log中的慢SQL也确实是这样。
原因：早上业务大量操作商家入驻。导致大量的慢事务，把表锁住了。所以导致查询缓慢。
优化：事务粒度细化，不需要保证事务的不用保证。





#### 幻读问题
在可重复读的隔离级别下。一个事务A查询，事务B写入或删除。则A在前后查询可能会存在行数不一致。这就是幻读。**幻读在当前读才会出现**
**MySQL 在第三种隔离级别下如何解决幻读呢？**
> MySQl使用间隙锁【范围行锁】和行锁共同组成一个（Next-Key Lock）。
> * 唯一索引上的等值查询，直接升级为行锁。
> * 普通索引的等值查询，退化为间隙锁。锁住满足条件的行。
> * 唯一索引上的范围查询，锁住所有条件的行。


#### 多个事务同时更改同一行数据
事务会持有记录的行锁。来控制并发。


#### 事务隔离级别
* 读未提交【read uncommitted】
> 其他事务未提交也能看到，存在脏读
* 读提交【read committed】
> 其他事务提交了才能看到，存在幻读
* 可重复读【non-repeatable read】
> 一个事务在任意时刻的数据总与启动时一致。
* 串行化【serializable】 
> 串行化执行

### MVCC
简介：多版本并发控制，MySQL事务就是基于这个实现的。
> 每次进行更新的时候，都会留下回滚日志
> 同一个数据在InnoDB中会存在多个版本。在可重复读这个版本隔离级别下。当事务启动的时候，就确定一个版本号。然后按照当前值和日志进行回滚到目标版本。
**回滚日志什么时候删除？**
当没有事务使用到这些回滚日志的时候就会删除。因此不推荐长事务




#### 面试QA
* **MySQL是如何保证数据不丢失的？**
> 因为MySQL在进行更新的时候，会写两个日志。redo log和bin log。然后采用二阶段提交。
> 过程：
> 1. 当事务执行完毕还未提交时，先写一份redo log 标记prepare
> 2. 写一份binlog
> 3. 然后事务提交时将redo log标记为commit
> 两种情况：
> * 若bin log不存在，则认为事务未提交。
> * 若bin log存在。但redo log不是commit；则会判断binlog是否完整。若完整则提交且生效。

* **InnoDB为什么要使用B+树，而不是二叉树？**
> 首先  B+树与二叉树的区别。 B+树是N叉树。先说查询效率，虽然二叉树要优于B+树。但是二叉树的查询会造成大量磁盘IO，而B+树不会造成大量磁盘IO。


* **自增主键和非自增主键有什么区别？**
> 自增主键每次都是在数据页后面添加。不会涉及到页分裂。写性能相对非自增主键较高。

* **你们线上用的什么隔离级别？ 为什么？**
> 读提交。  在性能上，可重复读在写的时候会使用间隙锁来解决幻读问题，会减少吞吐量。另外已经提交的数据其实读到也没有什么关系。牺牲小概率一致性来提升吞吐量。


* **Join表查询有什么问题？你们发生过吗？**
场景：
> 线上报大量慢SQL的日志。发现是测试在做压测。  
处理：
> 停止压测。
问题反思：
> 两站大表Join。  驱动表为关联关系表，被驱动表为业务实体表。数据量均为10w。
> 查看执行计划。发现均走了索引。只不过驱动关系有变化。
> SQL写的驱动是A驱动B。但是执行计划发现是B驱动A。且选择的索引有问题。理论上应该是表A中的记录去驱动表B的主键索引。但是实际不是。

原因：驱动表A的某个字段是字符串，但作为条件时传的是整形，因此导致没有选择对索引。于是优化器认为选择其他索引和更换驱动表为B时更优。因此实际执行的时候是B驱动A。导致B也没走主键索引。  

**本质原因是驱动表A没有走索引**