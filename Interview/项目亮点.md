1、商品系统本身的量级，包括流量、稳定性这条线
2、架构层面的体现
3、技术或者业务结果

面试层面除了要看本身负责的东西，还会看商品领域往外的延伸，以及这三个项目之间的联系，从erp-供应链商品-平台商品应该是一个整体。作为架构owner，架构的设计思路、问题、难点、扩展、稳定性等等，要考虑全面，都准备下。



我们要清晰的分辨出一个问题会带来哪些影响和损失，这些影响和损失在我们当前业务阶段是否可以接受？是否是瓶颈？同时我们也要清晰的了解要解决这些问题我们所要付出的代价。一定要综合评估，讲究一个投入产出比。某些问题虽然是问题，但是在某些阶段和场景下并不需要我们投入解决。而有些问题则对于我们当前业务发展阶段是瓶颈，我们**不得不**去解决。我们在架构设计或者程序设计中，方案一定要`简单`，`合适`。并预估一些提前量留有一定的`演化空间`。



可扩展性：

无状态：横向扩展，增强服务容错能力

松耦合：业务模块之间的松耦合，可以在不影响系统其他部分的情况下对该微服务或者模块进行横向扩展

异步处理：事件驱动，让服务直接的交互从同步等待响应转为异步，这种方式有助于缓解耦合，降低复杂系统中出现级联故障的风险

当然，异步也会带来一致性的问题复杂性，商品创建的异步设计



扩展策略：垂直扩展和水平扩展

垂直扩展：提升机器的CPU、内存、存储等性能，对于因一致性限制而难以水平分布的数据库来说，垂直扩展更可取

水平扩展：增加更多的机器来分担工作量，带来数据一致性问题，网络开销，以及分布式系统管理复杂性

例如分库分表的拆分数量







##### 线上 JVM 的调优



##### DDD落地

负责溯采供应链平台商品体系从 0 到 1 的 DDD 实践落地，制定 分层的商品领域模型，并根据模型进行微服务拆分。



##### 分库分表

使用 Sharding-JDBC 对商品铺货关系表进行 水平拆分，设计 平滑数据迁移方案。

使用数据库分片优化单节点数据过载问题。





##### 本地消息表 任务框架

通过 MQ和本地消息表 结合 任务框架 保证 千万级 铺货商品的 商品信息联动。

- 100w店铺商品 20w品铺货 8000w的link条关系  1w家小B  总共服务小B30w+ 采购单位700w+

- 铺货回采的业务场景是我们把商品创建到面向G端采购人的平台进行售卖，产生订单后会回流到我们这边。

- 铺货后的商品存在关联关系，如果我们供应链的商品发生信息变更或者库存调整，店铺商品变更先发消息，为了确保消息一定发成功，采用了本地消息表的方式，确保消息一定会发送成功

  - 写入业务操作和消息记录：

  - 在同一个事务中，执行业务操作，并将消息写入消息表中，消息表记录至少包含消息ID、消息内容、目标系统和状态等。

  - 事务提交后，业务操作和消息记录都会被持久化到数据库。

  - 发送消息和更新消息状态：

  - 发送消息到MQ（[消息队列](https://zhida.zhihu.com/search?content_id=245072008&content_type=Article&match_order=1&q=消息队列&zhida_source=entity)）系统。

  - 发送成功后，更新消息表状态为已发送。

  - 补偿任务处理：

  - 消息记录被写入消息表后，补偿任务会定期扫描消息表，寻找尚未被处理的消息，重新发送消息到MQ（消息队列）系统。

  - 消费端[幂等处理](https://zhida.zhihu.com/search?content_id=245072008&content_type=Article&match_order=1&q=幂等处理&zhida_source=entity)：

  - 消费者收到消息之后，需要确保操作具有幂等性，因为消息可能会被重复处理。

- 请求异步化解耦上下游依赖关系。



### 顺序消息

同一个消费者组Group内的不同消费者实例（机器）**不会同时消费同一个队列**。队列是消息存储的的最小单元，每个队列在同一时刻只能被一个消费者线程处理。

即使消费者实例启动了多个线程，每个线程仅处理**不同的队列**。一个队列的消息始终由**同一个消费者线程顺序处理**，避免多线程并发导致乱序。

这里的队列指的是消息队列MessageQueue，每个Topic可以配置多个消息队列，RocketMQ默认是MessageQueue。



#### 生产方

生产方线程通过实现**`MessageQueueSelector`** 接口，通过对分片键取模的方式，保证相同ID的商品变更消息会投放到同一个MessageQueue中。

在业务层面上我们通过分布式锁的方式保证一个商品的变更消息是顺序的，注意该消息的发送方式也必须要是同步发送才行。

#### 消息存储

Broker，会将所有消息按到达顺序追加到CommitLog文件，确保物理存储顺序与发送顺序一致。

#### 消费方

RocketMQ对提供了两种消费模式，一种是并发的消费方式 **MessageListenerConcurrently** ，和有序消费模式 **MessageListenerOrderly**，

要确保消费者注册的时候使用后者，每个消费者的消费端都是通过线程池的方式来消费消息的，只不过采用有序消费模式后，会分布式锁和本地锁来保证消息的有序消费。**确保同时只有一个消费者线程去消费一个消息队列中的消息。**

**即顺序消费模式使用3把锁来保证消费的顺序性：**

1.**broker端的分布式锁：**

- 在负载均衡的处理新分配队列的updateProcessQueueTableInRebalance方法，以及ConsumeMessageOrderlyService服务启动时的start方法中，都会尝试向broker申请当前消费者客户端分配到的messageQueue的分布式锁。
- broker端的分布式锁存储结构为ConcurrentMap<String/* group */, ConcurrentHashMap<MessageQueue, LockEntry>>，**该分布式锁保证同一个消费组consumerGroup下同一个消息队列messageQueue只会被分配给一个消费者客户端consumerClient。**
- 如果拿不到这个锁，则不会创建对应的ProcessQueue，同样也不会发送对应的消费请求。
- 获取到的broker端的分布式锁，在client端的表现形式为processQueue. locked属性为true，且该分布式锁在broker端默认60s过期，而在client端默认30s过期，因此ConsumeMessageOrderlyService#start会启动一个定时任务，每过20s向broker申请分布式锁，刷新过期时间。而负载均衡服务也是每20s进行一次负载均衡。

2.**messageQueue的本地synchronized锁：**

- 在执行消费任务的开头，便会获取该messageQueue的本地锁对象objLock，它是一个Object对象，然后通过synchronized实现锁定。
- 这个锁的锁对象存储在MessageQueueLock.mqLockTable属性中，结构为ConcurrentMap<MessageQueue, Object>，所以说，一个MessageQueue对应一个锁，不同的MessageQueue有不同的锁。
- 因为顺序消费也是通过线程池消费的，所以这个**synchronized锁用来当前这个消费者客户端中，保证同一时刻对于同一个队列只有一个消费线程去消费它。**

3.**ProcessQueue的本地consumeLock：**

- ProcessQueue ，它是一个队列消费快照，消息拉取的时候，会将实际消息体、拉取相关的操作存放在其中。还有消费状态处理、offset提交等功能层面都是由ProcessQueue提供。

- 在获取到前两把锁后，每次在执行真正的消息消费的逻辑messageListener#consumeMessage之前，会获取ProcessQueue的consumeLock，这把本地锁是一个ReentrantLock。**它的作用是防止消息被其他消费者客户端重复消费。**
- 因为在发生负载均衡的时候，消息队列可以会分配给新的消费者，那么当前客户端消费者需要对该队列进行释放，调用removeUnnecessaryMessageQueue方法请求broker端分布式锁的解锁。而在请求broker分布式锁解锁的时候，一个重要的操作就是首先尝试获取这个messageQueue对应的ProcessQueue的本地consumeLock。只有获取了这个锁，才能尝试请求broker端对该messageQueue的分布式锁解锁。
- 因为消费线程会拉取一批消息，在每次消费前都会加consumeLock，消费结束后释放consumeLock。如在消费过程中，消费了但还没提交消费位点，此时如果别的消费者客户端重新获取了当前消息队列，那么它也能拉到当前线程消费的消息，所以可能会导致消息重复消费。

参考：https://blog.csdn.net/weixin_43767015/article/details/121028059







##### 商品推荐

通过 数据分析 挖掘业务增长点，结合 NER 和 类目预测 对小B订单进行 商品推荐， 平均 提升有效GMV 26.7%。



##### 注解缓存组件

基于AOP 设计 通⽤注解缓存查询组件，低代码侵⼊，结合 多级缓存技术 提升核心链路性能70%。

**多级缓存/缓存一致性** 支持高性能

cache aside  先更新数据库 再删缓存，也可以异步化 通过canal+MQ 监听数据库变更来刷新缓存，最终保证缓存和数据库的最终一致

优点：可以减少操作缓存的时间

缺点：

引入中间件，需要保证中间件的高可用，会增加系统成本

相比同步操作，异步操作的一致性的时间会拉长，因为涉及到MQ就可能存在消息堆积的场景，这个需要从业务上考虑是否可以容忍这种情况。

每个微服务基于自己的业务去封装存储的细节，数据库也应该独立拆分，

大Key





##### 分布式事务

##### 分布式锁

测试环境 redis CLUSTER部署

10.11.3.234:6379,10.11.7.251:6379,10.11.9.221:6379,10.11.15.45:6379,10.11.2.140:6379,10.11.11.176:6379



##### 其他

商品发品

商品铺货

标准库的建设

线上CPU100% 问题排查

系统流量激增100倍





##### 职业规划发展

- 供应链方向：从最开始ERP商品，到后来的谊品供应链商品，再到现在的溯采平台商品，不同的商品系统的侧重点有所不同，导致商品的上

- C端方向：更靠近用户一些，对于系统设计上，并发流量上的挑战也会大一些。









分布式锁保证库存并发扣减的一致性

销售库存大多都是虚拟库存，所以采用的逻辑是 下单抠库存，取消支付返还库存，

插入库存扣减流水

看门狗自动续锁



**本地事务和分布式事务，使用rocketMQ的事务消息解决多节点的数据一致性问题。**

MQ

https://rocketmq.apache.org/zh/docs/featureBehavior/03fifomessage

- 不丢消息

  - 发送端

  - MQ端

  - 消费端



顺序消息

分区顺序消息

对于指定的一个Topic，所有消息根据Sharding Key进行区块分区，同一个分区内的消息按照严格的先进先出（FIFO）原则进行发布和消费。同一分区内的消息保证顺序，不同分区之间的消息顺序不做要求。

- 适用场景

  适用于性能要求高，以Sharding Key作为分区字段，在同一个区块中严格地按照先进先出（FIFO）原则进行消息发布和消费的场景。

- 示例

  - 用户注册需要发送验证码，以用户ID作为Sharding Key，那么同一个用户发送的消息都会按照发布的先后顺序来消费。
  - 电商的订单创建，以订单ID作为Sharding Key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照发布的先后顺序来消费。

- 云消息队列 RocketMQ 版服务端判定消息产生的顺序性是参照单一生产者、单一线程并发下消息发送的时序。如果发送方有多个生产者或者有多个线程并发发送消息，则此时只能以到达云消息队列 RocketMQ 版服务端的时序作为消息顺序的依据，和业务侧的发送顺序未必一致。



全局顺序消息实际上是一种特殊的分区顺序消息，即Topic中只有一个分区，因此全局顺序和分区顺序的实现原理相同。因为分区顺序消息有多个分区，所以分区顺序消息比全局顺序消息的并发度和性能更高。

消费者类型是集群消费类型



指标分区表 2917w
