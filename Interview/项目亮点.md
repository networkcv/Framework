## 软实力

有动作没结论

有结论没逻辑

有逻辑想的浅

想得深表达弱





可扩展性 scalability

可用性 availability

一致性 consistency







再讲应用架构  业务架构 再到应用架构

应用架构为什么这么设计

商品模型

1、商品系统本身的量级，包括流量、稳定性这条线
2、架构层面的体现
3、技术或者业务结果

面试层面除了要看本身负责的东西，还会看商品领域往外的延伸，以及这三个项目之间的联系，从erp-供应链商品-平台商品应该是一个整体。作为架构owner，架构的设计思路、问题、难点、扩展、稳定性等等，要考虑全面，都准备下。





项目解决了什么问题  我的角色 遇到了什么挑战 怎么解决的  通过解决这个问题有什么成长





- **业务思考提升**
  - 需要加强对市场动态和业务变化的了解与熟悉。
  - 提高对业务的整体理解和敏感度。
- **供给侧和技术宽度**
  - 深入思考供给侧的问题，提升相关深度。
  - 扩展技术知识的广度，弥补当前不足。
- **项目管理风险意识**
  - 当前已有一定的风险意识，但需进一步强化。
  - 在项目管理和整体推进上，应更加体制化和系统化。
- **自身优势的归纳总结**
  - 在讲述过程中，未能充分凸显个人能力的价值。
  - 应及时总结和归纳自身的优势，形成清晰的认知。
- **未来规划方向**
  - 当前规划偏重于业务层面，需在技术领域增加明确的方向和内容。
  - 结合自身优势，制定更全面的未来发展计划。





商品管理  6台   商品铺货 10台



我们要清晰的分辨出一个问题会带来哪些影响和损失，这些影响和损失在我们当前业务阶段是否可以接受？是否是瓶颈？同时我们也要清晰的了解要解决这些问题我们所要付出的代价。一定要综合评估，讲究一个投入产出比。某些问题虽然是问题，但是在某些阶段和场景下并不需要我们投入解决。而有些问题则对于我们当前业务发展阶段是瓶颈，我们不得不去解决。我们在架构设计或者程序设计中，方案一定要简单，合适。并预估一些提前量留有一定的演化空间。



redis 旁路缓存 提升



可扩展性：

无状态：横向扩展，增强服务容错能力

松耦合：业务模块之间的松耦合，可以在不影响系统其他部分的情况下对该微服务或者模块进行横向扩展

异步处理：事件驱动，让服务直接的交互从同步等待响应转为异步，这种方式有助于缓解耦合，降低复杂系统中出现级联故障的风险

当然，异步也会带来一致性的问题复杂性，商品创建的异步设计



扩展策略：垂直扩展和水平扩展

垂直扩展：提升机器的CPU、内存、存储等性能，对于因一致性限制而难以水平分布的数据库来说，垂直扩展更可取

水平扩展：增加更多的机器来分担工作量，带来数据一致性问题，网络开销，以及分布式系统管理复杂性

例如分库分表的拆分数量







## 自我介绍 TODO

## 业务架构能力

### 业务指标 QPS TPS 数据量

峰值QPS 3w 怎么扛

分库分表 缓存 机器 异步





### DDD落地

负责溯采供应链平台商品体系从 0 到 1 的 DDD 实践落地，制定分层的商品领域模型，并根据模型进行微服务拆分。



CQRS

这个和MySQL读写分离很相似。但是MySQL的读写分离强调的是物理数据库的分离，而CQRS更关注的是模型层面的分离。

首先最终目的一定是性能的提升。CQRS允许读取和写入的负载独立缩放，这样可以减少锁的竞争。同时它可以分离读写数据的存储结构，读和写使用不同的存储方式。比如command用db，query用es，这样可以针对性的进行优化。

虽然我们现在只在模型上分离，没有在存储上做分离，但是如果以后要分离存储的话，模型分离也是第一步。还有一点就是领域模型对象在构建时会有诸多检查和多次对象转换，使用query模型可以尽可能的避免这些点。

为什么使用DDD

毋庸置疑「领域」在 DDD 中占据了核心的地位，DDD 通过领域对象之间的交互实现业务逻辑与流程，并通过分层的方式将业务逻辑剥离出来，单独进行维护，从而控制业务本身的复杂度

所以我们才需要用DDD的分层思想去重构一下以上的代码，通过不同的代码分层和规范，拆分出逻辑清晰，职责明确的分层和模块，也便于一些通用能力的沉淀。

- **DDD可以很好的指导微服务拆分和演进。**

  通过DDD 的方法来建立领域模型，划分领域边界，再根据这些领域边界从业务视角来划分微服务边界。可以很好地实现微服务的“高内聚、低耦合”。这样就解决了拆分的问题；其次微服务内部的实体都是以聚合为单位的（传统可能是按照类型比如service，pojo），聚合内实现了高内聚的业务逻辑。如果该微服务后边需要更细粒度的拆分，就可以按照聚合进行拆分，这样可以更好的进行服务演进。

  比如老商品拆分后分为商品基础数据服务、销售商品服务、供应链货品服务，而商品基础数据服务中的主档、类目、品牌、属性标签都是按聚合划分的，后期演进时可以拆成独立的服务。

- **实体采用充血模型对核心业务进行沉淀。**

  这点是DDD和三层架构的一个比较大的区别，传统的services层中承接全部的业务逻辑，可能会包含部分重复使用但比较核心的业务逻辑。将其中部分逻辑向下沉淀，针对同一实体相关的业务逻辑都在实体类中实现，跨多个实体的逻辑在领域服务内实现。领域服务通过组合编排实体的方法，供上层的应用服务调用。这样就构成了领域层的核心。（其他还有仓储层的接口）

  DDD提倡充血模型，尽量将业务逻辑归属到实体对象上（或者领域服务里）。在设计时我们主要考虑实体自身的属性和业务行为，实现领域模型的核心行为，不必过多考虑外部操作和业务流程，这样才能保证领域模型的稳定性。

  举个例子：一个运营下架所有商品，这个需求中，商品的上下架是商品实体的行为，属于领域层。而下架所有商品，这就要判断他是否有对应操作权限，属于应用层。比如他只能下架他品类权限内的商品，这个就是数据应用层的业务逻辑。

- **仓储层不再是简单的DAO，它可以将领域模型和数据模型解耦**

  仓储层会将内存中的领域对象进行持久化操作，领域层无须关注具体存储哪张表，怎么存。只需要关注业务逻辑。

  仓储层处理基础单元是聚合根，是服务于实体的，而不是具体的表。

- **CQRS将复杂查询摆脱领域模型的限制，分离领域模型和查询功能**

  由于构建领域对象的完整性约束，所以构建一个领域实体，往往还要去构建它包含的其他实体或者值对象。构建过程比较麻烦。

  其次从DTO=〉command=〉DO=〉PO 要经过多次对象转换。

  这些在查询的场景下完全是不需要的，查询时更希望以简单DTO展现查询结果。CQRS可以帮我们很好的解决这一点。

- **建立通用语言减少沟通成本。**

  确保业务术语没有二义性，可以帮助开发、测试、产品、运营、业务更好沟通。比如商品域中的主档、商品、货品 这些名词都对应领域实体，像 上架、下架、在售、停售 这些动词都代表实体行为。这个在商品域里边可能体现的不够明显，但是在金融、保险这类专业词汇较多的行业内有很好的效果。

**前期准备**

- 首先是跟产品对齐商品的模型和核心的业务逻辑。
- 针对之前接口大而全的问题，包括使用场景不明确的问题，找外域进行接口梳理，包括接口的出入参、使用场景和使用字段，然后整理成表格。消息梳理也同时在进行。
- 根据整理出来的表格，梳理业务与外域诉求，细分接口职能，定义核心原子服务。
- 将改动内容总结为接口替换表和消息替换表格给到外域，包括预计上线的时间。
- 当然我们这里不是一刀切，因为涉及外域的比较多，改造内容也比较多。线上新老接口会同时保留，新老消息也都会进行发送。新老数据也会做同步。只不过老的部分不动了，只在新的上做开发，这样逐步去推动外域做改造。

**代码落地**

在工程中，我们使用CQRS架构，充血模型来落地。首先明确聚合。例如门店、仓库、公司等等是聚合根。 聚合根：具有全局标识 实体：只在聚合内有唯一标识。
在分层架构中，接口层调用应用服务层，应用服务层仅负责业务逻辑，比如说调用领域对象的行为。 例如现在有一个保存门店的方法。 在内存中构建出来一个门店对象，然后调用门店对象的行为来对内存中的领域对象进行修改。 同时行为会产生事件。 事件会存储在对象内部。当调用仓储层store方法提交事务之后，会调用事件发布将这些事件发布出去。 后续会有监听来实现 缓存清理和消息发送。

**数据同步**



**DDD-遇到问题**

第一个就是消息一致性问题。因为消息是由事件来驱动。 而消息又是业务中比较重要的一环。万一事务提交了但是消息因为各种原因发送失败了，那么对于下游业务就会存在问题。存在分布式一致性问题。

**解决：**
对于业务消息，我们更改了方案，采用本地消息表，在事务中写表。然后异步线程会去发送这条消息。并将其置为已发送。 当时也考虑要引入其他团队开发的 分布式流程任务引擎来解决一致性问题，考虑到成本比较高，且我们编辑的情况不多，就采用了本地消息表。





## 项目管理能力

## 分布式设计

### 分布式事务

 保证分布式事务的最终一致性。

**1. 本地消息表**

**本地消息表**是一种在本地数据库中维护消息状态的机制，通常用于实现分布式事务的最终一致性。它通过在本地数据库中记录消息的发送状态，确保消息的可靠发送。

本地消息表字段：业务id，业务类型，消息内容，消息状态（待投递、成功或失败），消息描述，创建时间，重试次数

- 应用程序在本地数据库中插入一条消息记录，标记为“待发送”状态。
- 通过定时应用程序调用消息中间件（如RocketMQ）发送消息。
- 如果消息发送成功，更新本地消息表中的记录状态为“已发送”。
- 如果消息发送失败，应用程序定期重试发送。

**优点**

- **简单易实现**：通过本地数据库记录消息状态，实现相对简单。
- **可靠性高**：通过重试机制确保消息的可靠发送。
- **最终一致性**：通过本地消息表和消息中间件的结合，最终确保消息的发送和消费。

**缺点**

- **性能问题**：数据库操作可能会成为性能瓶颈，尤其是在高并发场景下。
- **依赖数据库**：依赖本地数据库的可靠性，如果数据库故障，可能会导致消息丢失。

**2. 事务消息**

**事务消息**是一种由消息中间件提供的机制，用于确保消息的发送和本地事务的提交是原子性的。它通过两阶段提交协议来实现分布式事务的一致性。

- 应用程序开始一个本地事务。
- 应用程序调用消息中间件发送消息，消息中间件进入“半消息”状态。
- 应用程序提交本地事务。
- 消息中间件检查本地事务是否成功提交，如果成功，则将“半消息”标记为“可投递”状态；如果失败，则丢弃“半消息”。

**优点**

- **强一致性**：通过两阶段提交协议，确保消息的发送和本地事务的提交是原子性的。
- **性能优化**：消息中间件通常会进行性能优化，减少数据库操作的开销。
- **简化开发**：由消息中间件管理事务的一致性，减少了应用层的复杂性。

**缺点**

- **复杂性**：两阶段提交协议本身比较复杂，可能会引入额外的性能开销。
- **依赖中间件**：依赖消息中间件的事务管理能力，如果中间件故障，可能会导致事务不一致。
- **回查机制**：在某些情况下，可能需要回查本地事务的状态，增加了系统的复杂性。

3. **比较**

| 特性           | 本地消息表               | 事务消息               |
| -------------- | ------------------------ | ---------------------- |
| **实现复杂度** | 简单，依赖本地数据库     | 复杂，依赖消息中间件   |
| **一致性**     | 最终一致性               | 强一致性               |
| **性能**       | 可能成为瓶颈             | 通常更优               |
| **依赖**       | 本地数据库               | 消息中间件             |
| **适用场景**   | 读多写少，对性能要求不高 | 高并发，对一致性要求高 |

**4. 适用场景**

- **本地消息表**：
  - 适用于读多写少的场景，对性能要求不高，但需要确保消息的最终一致性。
  - 适用于对消息发送的可靠性要求较高，但可以接受一定的延迟。
- **事务消息**：
  - 适用于高并发场景，对消息的一致性要求较高。
  - 适用于需要强一致性的业务场景，如金融交易、订单处理等。





### 本地消息表 任务框架 亿级商品信息联动

通过 MQ和本地消息表 结合 任务框架 保证 亿级 铺货商品的 商品信息联动。

**数据现状** 23年开始 100w的商品 20w存在铺货 30w的小B中 存在铺货的小B有5w  至24年中总共铺货关系2000w，到25年中总共铺货关系近1亿。

这个铺货关系一端是我们供应链平台的货品，另一端是交易平台的销售商品，是一对多的关系。如果我们平台的商品发生了变更，我们的业务需要根据供货关系同步到交易平台对应的销售商品，例如商品信息、价格、库存这些。

因为联动的商品数据量可能会比较大，而且可能中间出现各种异常的场景，为了确保变更结果一定能够触达到我们的小B用户，所以自己实现的一套任务框架来完成信息的联动的。而联动任务的创建则是基于商品变更的领域消息来做的。

如果销售商品是一品一规，而供货商品是一品多规的场景，那么一个供货商品在销售端端一个店铺中可能会关联多个销售商品



### 本地消息表和事务消息对比

**优点：**

1. 实现简单，只使用一张消息表来维护消息的发送状态。
2. 容错性较高，如果消息发送失败，可以使用补偿任务重新发送。
3. 实现了分布式系统中数据的最终一致性。

**缺点：**

1. 数据一致性延迟较高，由于依赖异步消息传递，不能立即保证数据一致性，只能实现最终一致性。

<img src="img/项目亮点/v2-988c00321ca1cdfacbf04ce1d5163efc_1440w.jpg" alt="img" style="zoom: 67%;" />





## Java

研读过 JDK 源码，如集合、ThreadLocal、线程池、AQS 等基础框架； 

### 泛型

### ThreadLocal 原理 TODO

threadlocal 是线程本地变量，

ThreadLocal 内部有一个静态内部类 ThreadLocalMap 这个Map的key是ThreadLocal对象，Value是我们要存储的值。

这里的key和value会包装成一个Entry对象，这个Entry是ThreadLocalMap的静态内部类，同时继承自 WeakReferene 。表示Entry的key 存放的ThreadLocal对象是弱引用的。

每个线程 Thread内部都会持有一个ThreadLocalMap对象threadLocals，这个对象是每条线程用来存储当前线程对应的threadlocal变量信息的，后续通过threadlocal.get()的时候，也是先拿到当前线程的threadLocals对象，然后再根据 threadLocal 获取 value。

在向 ThreadLocalMap 添加元素的时候，如果遇到hash冲突会通过开放寻址法中的 **线性探测** 来实现，这里没有像HashMap一样使用拉链法的原因是，拉链法更适合于解决频繁产生哈希冲突的场景，Thread持有的ThreadLocal对象不会很多，所以这里发生的hash冲突的几率是比较小的。

### AQS原理

### 线程池原理

[Java线程池实现原理及其在美团业务中的实践](https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html)

**创建Worker**

具体的worker工作线程 继承了AQS类实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。

![图7 Worker执行任务](img/项目亮点/03268b9dc49bd30bb63064421bb036bf90315.png)

 如果执行中的线程抛出了未捕获的异常，那么会根据任务的提交方式不同决定线程是否销毁，如果是submit任务的话，工作线程抛出的异常会被捕获存放到对应的Future中，所以线程不会销毁。如果是execute任务的话，抛出未捕获的运行时异常，线程会中断。



### 线程池死锁

https://juejin.cn/post/7065098084606279693

父子异步任务公用一个线程池，当并发度比较高的时候，父方法会直接将核心线程数打满，等到子方法中将任务在提交异步任务到线程池后，核心线程就被挂起，阻塞在子异步任务的future返回上，子方法需要核心线程来执行任务，但所有的核心线程都被挂起了，导致了线程池死锁。

**排查过程**



后续action：

**线程池改造**

借鉴了tomcat的线程策略

JDK 默认线程池是 先创建核心线程 再添加队列 队列满了才创建非核心线程。

tomcat 先创建核心线程 然后创建非核心线程 最后才添加队列。

简单来说就是重写了execute()方法，当抛出拒绝策略了尝试一次往阻塞队列里插入任务，尽最大努力的去执行任务，新增阻塞队列继承了 LinkedBlockingQueue，重写了offer()方法，重写了offer()方法，每次向队列插入任务，判断如果当前线程数小于最大线程数则插入失败。进而让线程池创建新线程来处理任务。

**线程池设置问题**

核心线程池数设置过小，没有做好流量预估，导致触发拒绝策略 和 接口降级

线程池阻塞队列设置过长，最大线程数设置失效，导致请求数量增加时，大量任务堆积在队列中，任务执行时间过长，最终导致下游服务的大量调用超时失败。

**动态线程池**：

因为线程池的参数需要根据线上业务实际情况进行合理的设置，需要不断的观察和调整，所以线程池需要支持动态的配置，为了方便调整配置，所以我们将配置参数保存在我们已有的分布式配置中心apollo上，通过apollo的配置监听功能，监听对应的参数变化然后去修改我们对应的线程池参数。

```java
@Component
public class SomeBean {
    @Value("${request.timeout:200}")
    private int timeout;
 
    @ApolloConfigChangeListener
    private void someChangeHandler(ConfigChangeEvent changeEvent) {
        if (changeEvent.isChanged("request.timeout")) {
            refreshTimeout();
        }
    }
}
```



如果动态设置了setCorePoolSize，会直接覆盖之前的corePoolSize值，并且基于当前值和原始值的比较结果采取不同的处理策略。对于当前值小于当前工作线程数的情况，说明有多余的worker线程，此时会向当前空闲worker线程发起中断请求以实现回收，多余的worker在下次idel的时候也会被回收；对于当前值大于原始值且当前队列中有待执行任务，则线程池会创建新的worker线程来执行队列任务

**线程池监控**：

监控线程池的状态、核心参数、以及任务挤压到一定程度的预警，或者触发拒绝策略的









## JVM

熟悉 JVM，如 JMM、类加载机制、GC算法，进⾏过线上 JVM 的调优； 

### G1和CMS区别 TODO

可预测的停顿模型、动态分区，保留了分区的概念，但没有垃圾分代，

### JVM调优 TODO

### GC问题排查 JVM优化

早期出现这个问题的时候 我们用的是2核4G的机器，一共4台。用的是CMS+ParNew

JVM 占用了2G  新生：老年 是 1:2  新生代占1/3    调整到 4/10

**调整新生代比例**，以及JVM实例子占用机器的内存

我们线上的GC情况是 老年代的垃圾回收次数很少，但新生代很频繁

增大新生代比例。 只需要修改JVM参数配置即可， 说起来很简单， 但是需要多次调整并 进行压测， 最终找到一个平衡点， 在保证Full GC的频次和耗时都在合理范围内的前提 下， 把Young GC频次降到最低。

贸然增大新生代比例， 虽然可能降低GC的频次，但是会导致单次GC耗时增加。

首先， 我们需要先明确， 目前主流的新生代收集器大多采用标记-复制算法， ParNew也 一样。 研究表明， 绝大多数应用场景， 新生代中98%的对象生命周期很短， 在毫秒级 别， 基本上被使用一次后就会变成垃圾对象， 会在下一次GC时被清理掉。 在很多JVM中 将堆内存分为一块较大的Eden空间和两块较小的Survivor空间(下图的S0和S1)， 新生对 象存放在Eden区。 当发生Young GC时， 将Eden和当前Survivor中存活的对象一次性复 制到另外一块Survivor中， 最后整体清理Eden和当前的Survivor空间。 每次Young GC 时两块Survivor区互相更换。 HotSpot虚拟机默认Eden和两块Survivor的大小比例是 8:1:1， 也就是说每次新生代中可用内存为整个新生代容量的90%（80%+10%）， 只有 10%的内存会被“浪费”。

现在我们清楚了ParNew回收器采用了标记-复制算法。 现在来分析一下ParNew回收器 GC耗时和新生代大小的关系。 我们知道标记-复制算法分为两个阶段， 标记阶段和复制阶 段。 为了简化问题我们暂且认为标记阶段只扫描新生代的存活对象， 其实该阶段还需要扫 描部分老年代对象。 假设我们要把新生代扩容1.5倍。

• 扩容前：新生代容量为2G， 假设某对象A的存活时间为600ms， Young GC间隔 500ms， 那么本次GC时间 = 扫描新生代时间 + 复制对象时间（Eden和当前Survivor复 制到另一个Survivor）。

• 扩容后：新生代容量为3G ， 对象A的生命周期为600ms， 但是由于新生代扩容了1.5 倍， 所以Young GC间隔理论上增加到了750ms。 此时发生Young GC， 对象A已经用完 了生命周期， 成为了垃圾对象， 就不需要把对象A复制到另一个Survivor区了。 那么本次 GC时间 = 1.5 × 扫描新生代时间， 没有增加复制时间。

所以， 当扩大新生代容量时， 实际上每次GC需要复制的存活对象并不会按照扩容比例递 增。 容量扩大到1.5倍， 增加的存活对象会远小于1.5倍。 虽然标记阶段消耗的时间提高到 了1.5倍， 但是复制阶段耗时并没有明显提高。 更重要的是， 对于虚拟机来说， 复制对象 的成本要远高于扫描标记的成本， 所以， 单次Young GC时间更多取决于存活对象的数 量， 而非Eden区的大小。 所以， 如果堆内存中存在大量短生命周期的对象（大部分场景 是这样的）， 那么扩容新生代后， Young GC时间不会显著增加。

经过反复调试和压测后， 我们把新生代调整到了2.9G。 机器配置所限， 整个堆内存大小 没变， 保持在8G。

**分代调整**

此外， 观察了各代龄的对象数量情况后， 对代龄设置也做了调整。

前文提到， 当发生Young GC时， 会将Eden和当前的Survivor中存活的对象一次性复制 到另外一块Survivor中， 最后整体清理Eden和当前的Survivor空间。 每次Young GC时 两块Survivor区会互相更换。 存活对象在两块Survivor区之间每交换一次， 对象年龄就 会增长一岁。 直到达到MaxTenuringThreshold设置的年龄（默认是15岁）时， 相应的 对象就会被转移到老年代。 所以为了减少复制成本， MaxTenuringThreshold要尽量合 理， 不能设置太大， 否则有些长寿对象在每次GC时都会在两个Survivor区之间来回复 制， 无疑是增加了复制阶段的耗时。

 在15个分代中， 7岁以上的对象80%都会被转移到老年代（769.02除以980.48 ≈ 80% ）。 于是我们把 MaxTenuringThreshold 的值调整为 7， 将年龄超过7岁的对象 直接转移到老年代。 这样就减少了长寿对象在两个 survivor 区之间来回复制带来的性能 开销。

**最终**

经 过 一 轮 调 整 和 压 测 ， 最 终 新 生 代 调 整 到 了 2.9G ， 整 个 堆 内 存 保 持 8G 不 变 ， MaxTenuringThreshold调成了7。 新生代增大了将近1.5倍， Young GC 的频率减少了 大概1/3。 GC 的吞量提高了3.8%， 达到了96.8%， 。 Young GC 平均耗时稍有上升， 从 60ms上升到了71ms， 基本符合预期。 另外Full GC 的频率和耗时也在可接受的范围。



## Redis

[Redis.md](../Database/Redis/Redis.md)

熟练掌握 Redis，对底层数据结构、持久化机制有深⼊解

### Redis为什么快

1. **基于内存操作**

   相较于硬盘来讲速度更快，高吞吐和低延迟，因为硬盘是物理结构，一次读取包含磁头的寻道时间+盘片旋转将数据所在扇区移至磁头下方+数据传输时间

   

2. **基于单线程操作**

   减少线程上下文切换，多线程会带来频繁的上下文切换

   减少锁竞争带来的开销，如果存在锁竞争，那么没抢到锁的线程会被阻塞，这个过程中涉及到系统调用，而系统调用的产生会从用户态切换到内核态，这个过程也需要保存上下文信息，对性能有影响。（vmstat 是针对CPU、内存的监控工具，可以通过 cs 查看切换次数）

   作为Reids本身来讲，它是一个基于内存的非关型数据库，它的性能瓶颈其实不在CPU，而是在内存和网络IO，例如内存分配的大小，包括key的存活和失效，读写的时候网络的带宽以及传输过程中IO的效率。

   redis6.0 增加了多线程来处理IO 部分的读写，核心的计算逻辑还是由redis 主线程来完成。	 

3. **IO多路复用模型**

   [think of Java：Java IO](../Java/JavaBase/md/think of Java：Java IO.md)

   UNIX中定义的IO模型通常包含两个阶段：

   1. 等待数据准备好
   2. 将数据从内核缓冲区复制到用户空间（实际的IO操作）

   **同步阻塞IO**：用户空间中调用recvfrom，发生系统调用，如果内核缓冲区没准备好数据，那么线程在此期间会一直等待。

   **同步非阻塞**IO：用户空间中调用recvfrom前，将socket设置为非阻塞，这样当内核缓冲区数据没有准备好的时候，线程不会等待，而是直接返回一个错误，然后由调用方去不停的轮训数据是否准备好。

   **IO多路复用**：Linux内核提供了select/poll/epoll函数来支持由一个线程监听一组socket的数据是否处于准备就绪，当某个socket数据准备就绪后，select等函数会返回对应的连接，再真正调用recvfrom函数将数据从内核复制到用户态返回。本质上还是同步IO。

   

4. **高效的内部数据结构**

   SDS：简单动态字符串，是string类型的底层数据结构之一。

   QuickList：快速链表，是list类型的底层数据结构。

   ZipList：压缩列表，是hash类型的底层数据结构之一。

   ZSkipList：跳表，是zset类型的底层数据结果之一。跳表其实就是对普通的有序链表建立了索引层，比如将有序链表中的奇数节点提取到上一级，这样可以就可以借助二分查找到思想加快链表的遍历和读写操作。



### 分布式锁

当多个分布式系统需要竞争同一资源时，例如商品的创建、更新、库存的扣减都会用到分布式锁，来保证资源的互斥访问。

**三种实现方式：**

**mysql 实现**：通过唯一索引实现锁，优点：简单易懂，缺点：数据库连接数有限，在高并发下会成为性能瓶颈，而且锁的可靠性依赖数据库，一旦数据库故障，锁会失效。

**redis 实现**：通常是使用 SET NX + PX 过期时间，优点：性能会比较好，缺点：redis单节点故障问题，如果主节点挂了，从节点还没有同步，会导致锁丢失。

```java
SET resource_name my_random_value NX PX 30000
NX：仅在不存在 key 的时候才能被执行成功；PX：失效时间，传入 30000，就是 30s 后自动释放锁；
```

**zk 实现**：基于强一致性，通过临时有序节点实现 优点： 能够很好的保证锁的公平性和可靠性，缺点：在高并发的场景下，zk的写操作需要集群内的投票，会有一定的延迟。

**使用注意：**

在使用上还要注意尽量细化锁的粒度，以及设置好锁的过期时间，并且还要有锁的自动续租机制，避免锁提前失效。

在加锁的时候，将value设置为当前获取锁的线程，防止其他线程释放当前线程的锁。（考虑到线程id可能会重复，可以通过拼接全局唯一的信息，如当前节点的分片序号）

在释放锁的时候，根据value判断删除的线程id是否为加锁的线程id，如果一致才能进行删除，其中需要通过lua脚本来保证 get 和 del 命令的原子操作。

### Redisson

redisson 是 redis 官方推荐的Java版客户端，它在通信上是基于NIO的netty框架，保证网络通信的高性能，并且提供了多种功能的分布式锁实现，如：可重入锁（ReentrantLock）、公平锁（FairLock）红锁（RedLock）联锁（MultiLock）、读写锁（ReadWriteLock）等。

**可重入锁ReentrantLock实现**

底层是通过hash这种数据结构，结合lua脚本实现了锁的可重入，通过将线程id设置hash的 field，将锁的重入次数设置value。

**公平锁FairLock实现**

实现类似于AQS的原理。

排队机制：使用Redis的List结构维护等待队列

订阅发布：通过Redis的pub/sub通知下一个等待者

双重检查：获取锁时检查自己是否在队列头部

**联锁MultiLock实现**

同时对多个key同时进行加锁，所有的锁加锁成功才返回成功。整个操作是在lua脚本中保证原子性。

顺序加锁：按传入锁的顺序依次尝试获取

失败回滚：任意一个锁获取失败时，释放已获得的所有锁

统一过期时间：所有锁使用相同的过期时间

**红锁RedLock实现(不建议使用)**

如果对分布式锁的性能、可靠性、容错性方面有很高的要求的话，可以使用分布式锁的集群方案，这样能通过集群的容错性，来避免单节点故障。但是集群下锁仍然可能因为故障转移而导致失效。如：

1. 客户端 A 从 master 获取到锁
2. 在 master 将锁同步到 slave 之前，master 宕掉了。
3. slave 节点被晋级为 master 节点
4. 客户端 B 从新的master 节点获取到同一把锁。

针对这个问题，Redis 作者 提出了RedLock的概念，核心思路是通过多个redis的master节点来实现锁的获取和释放，提高可靠性。只有当**超过半数的实例加锁成功**后才认为获取到锁（同时也要满足整体加锁时间小于锁过期时间的一半）。这个就需要使用者来保证加锁的key分散在不同的master节点上。

而且该算法依赖系统时钟的准确性，如果多个节点的时间同步存在差异，可能导致锁提前失效，引发安全问题。

还有在性能是







RedLock的底层实现是基于联锁MultiLock的，联锁是要求所有key都加锁成功，而红锁要求半数加锁成功。



### Redis 集群模式

测试环境 redis CLUSTER部署 6台机器

10.11.3.234:6379,10.11.7.251:6379,10.11.9.221:6379,10.11.15.45:6379,10.11.2.140:6379,10.11.11.176:6379

Redis 集群中，如果某台节点（Master 节点）挂了，Redis Cluster 会自动执行故障转移，将挂了的Master 节点的从节点（Slave）提升为新的Master 节点，从而保证集群的正常运行。

需要注意的是，如果集群中某个Master 节点挂了，且该节点没有从节点，那么这个集群就会挂掉。所以为了保证集群的高可用性，建议每个Master 节点都有至少一个从节点。

**Redis 哈希槽**

2^14=16384 没有用一致性hash。原因是一致性哈希的节点分布基于圆环，无法很好的手动设置数据分布。











### 商品数据缓存 TODO



### 注解缓存组件 多级缓存

基于AOP 设计 通⽤注解缓存查询组件，低代码侵⼊，结合多级缓存技术 提升核心链路性能70%。

[Spring Cache缓存使用问题整理](https://blog.csdn.net/youbl/article/details/113052502)



1. 基于注解，不侵入代码，使用Spring AOP实现，轻量级，相比Spring 提供的注解缓存，可扩展性更高一些。

2. kernelCache缓存的删除是基于binlog的，基础架构会将bin log解析发送至消息队列，我们监听消息去处理删缓存，这里也可以做一些延时双删的操作，来保证db缓存的一致性。也可以由业务逻辑内自行进行缓存删除。

3. 还有一些都是默认的Redis缓存实现不支持，需要去实现相关扩展接口的。

   - 默认的RedisCacheManager是使用JDK的序列化，性能差；我们自己的缓存组件也就是kernelCache，是可配置序列化方式，默认gson。

   - 默认的是无法配置不同的缓存过期时间；kernelcache可以根据缓存枚举中的过期时间时间来差异化配置。

   - 默认是同步写缓存的，而kernelCache是异步线程池写缓存。





**多级缓存/缓存一致性** 支持高性能

cache aside  先更新数据库 再删缓存，也可以异步化 通过canal+MQ 监听数据库变更来刷新缓存，最终保证缓存和数据库的最终一致

优点：可以减少操作缓存的时间

缺点：

引入中间件，需要保证中间件的高可用，会增加系统成本

相比同步操作，异步操作的一致性的时间会拉长，因为涉及到MQ就可能存在消息堆积的场景，这个需要从业务上考虑是否可以容忍这种情况。

每个微服务基于自己的业务去封装存储的细节，数据库也应该独立拆分，

大Key





并且，为了防止缓存雪崩问题、缓存击穿问题，我们通常会采用多级缓存的解决方案，所谓的多级缓存就是：分布式缓存（Redis 或 Memcached）+本地缓存（Guava Cache 或 Caffeine）。因为分布式缓存可能会失效、可能会挂掉，所以为了系统的稳定性，多级缓存策略使用的非常广泛。

那么，问题来了，怎么保证本地缓存的一致性？

> 所谓的一致性是指在同时使用缓存和数据库的场景下，要确保数据在缓存与数据库中的更新操作保持同步。也就是当对数据进行修改时，无论是先修改缓存还是先修改数据库，最终都要保证两者的数据是一样的，不会出现数据不一样的问题。

#### 1.如何保证本地缓存的一致性？

在分布式系统中，使用本地缓存最大的问题就是一致性问题，所谓的一致性问题指的是当数据库发生数据变更时，缓存也要跟着一起变更。而分布式系统中每台机器都有自己的本地缓存，所以想要保证（本地缓存的）一致性是一个比较难的问题，但通过以下手段可以最大程度的保证本地缓存的一致性问题。

**① 设置本地缓存短时间内失效**

设置本地缓存短时间内失效，短的存活周期，保证了数据的时效性比较高，当数据失效之后，再次访问数据就会拉取新的数据了，这样能尽可能的保证数据的一致性。

它的特点是：代码实现简单，不需要写多余的代码；缺点是，效果不是很明显，不适合高并发的系统。

**② 通过配置中心协调和同步**

通过微服务中的配置中心（例如 Nacos）来协调，因为所有服务器都会连接到配置中心，所以当数据修改之后，可以修改配置中心的配置，然后配置中心再把配置变更的事件推送给各个服务，各个服务感知到配置中心的配置发生更改之后，再更新自己的本地缓存，这样就实现了本地缓存的数据一致性。

**③ 本地缓存自动更新功能**

使用本地缓存框架的自动更新功能，例如 Caffeine 中的 refresh 功能来自动刷新缓存，这样就可以设置很短的时间来更新最新的数据，从而也能尽可能的保证数据的一致性，如下代码所示：

```java
// 创建 Caffeine 缓存实例
Cache<String, String> caffeineCache = Caffeine.newBuilder()
// 设置缓存项在 5s 后开始自动更新
.refreshAfterWrite(5, TimeUnit.SECONDS)
// 自定义缓存更新逻辑（即获取新值逻辑）
.build(new CacheLoader<String, String>() {
    @Override
    public void reload(String key, String oldValue) throws Exception {
        // 模拟更新缓存的操作
        updateCache(key, oldValue);
    }
});
```

#### 2.实际工作中会使用哪种方案？

不同的业务系统，会采用不同的解决方案，例如以下这些场景和对应的解决方案：

- 如果对数据一致性要求不是很高，并且程序的并发压力不大的情况下，可能使用方案 1，也就是设置本地缓存短时间内失效的解决方案，因为它的实现最简单。

- 如果对数据的一致性要求极高，且有配置中心的情况下，可使用配置中心协调和同步本地缓存。

- 相反，如果对一致性要求没有那么高，且为高并发的系统，那么可以采用本地缓存的自动更新功能来实现。

  

在多级缓存中，本地缓存是不可或缺的组成部分，而想要保证本地缓存的数据一致性，可能采用：设置较短的本地缓存过期时间、通过配置中心来协调和同步本地缓存，以及使用本地缓存框架的自动更新功能保证数据的一致性等解决方案，而不同的业务场景，选择的解决方案也是不同的。







## MySQL

熟练掌握 MySQL，对索引、数据库锁、MVCC有深⼊理解； 

数据库指标

10台 每台 400 DB支持最大8000连接

版本是5.6 升 8.0



### 数据库锁

[MySQL.md](/Users/networkcavalry/Documents/GitHub/Framework/Database/MySQL/MySQL.md)





### 大表添加字段

[大表加锁 Online DDL](https://blog.csdn.net/qq_26664043/article/details/132067933)



MySQL 8.0 对 DDL  的实现重新进行了设计，Online DDL  支持 instant 算法，可以更快的添加列 和 字段默认值。

其原理是 只需修改数据字典中的元数据，无需拷贝数据也无需重建表，同样也无需加排他 MDL 锁，原表数据也不受影响。整个 DDL 过程几乎是瞬间完成的，也不会阻塞 DML。




在线DDL功能的实现涉及以下关键步骤和优化：1 创建临时表：通过创建临时表来存储将要进行的DDL操作所需的新结构。这样，旧表仍然可用于读写操作。
2 数据复制和同步：将旧表中的数据逐步复制到临时表中，并保持旧表数据与临时表数据的同步。这一过程确保了数据在DDL操作期间的完整性和一致性。
3 变更捕获和重放：通过使用日志和重做日志等机制，捕获在执行DDL操作期间发生的数据变更，并将其重放到临时表中。这确保了DDL操作完成后数据的一致性。
4 最终切换：当DDL操作完成时，数据库引擎将在适当的时机切换到临时表，使其成为新的表结构，并且对新表进行后续的读写操作。



### 分库分表 数据平滑迁移

使用 Sharding-JDBC 对商品铺货关系表进行 水平拆分，优化单节点数据过载问题。设计 平滑数据迁移方案。

**业务背景** 我们有一个铺货关系表，用于维护小B的货物供给关系，该表当时差不多2000w数据，因为和其他业务的表存在同一个数据库中，所以出现慢SQL等异常情况时会响应其他表的业务，为了提升系统整体的可靠性和稳定性，以及保证该表后续的读写性能，所以我们将该表从原有的数据库中迁移，在迁移中进行水平拆分，同时要保证数据的平滑迁移。

**问题**  大表添加字段的问题 数据库设计规范中新加字段必须要默认值，数据库版本升级从5.6 升级到 8.0 ，出现慢SQL影响其他业务 

需要物理删除的数据 在同一个事务中，转移点开归档表 ，归档表中会创建代理主键，删除时间，删除原因，删除人id

**数据现状** 23年开始 100w的商品 20w存在铺货 30w的小B中 存在铺货的小B有5w  **至24年中一年内总共铺货关系2000w**

**容量规划** 1w家活跃店铺平均铺货1w个商品，**当时预估从24年中至25年中能能增长1亿。至2027年中能增长到10亿**。考虑到成本和这张表的读写压力，按照单表1000w纬度，差不多需要100张表。所以我们4库128表，其中4个库分布在2个实例下，每库32表，累积2x2x32=128张表。如果后续实例压力提升可以去进行实例配置升级或者进行数据库迁移至新实例，升级成本较小。

**数据迁移** 

整个过程包含：

- 前期准备
  - 确定方案，开发数据迁移脚本
  - 确定分库分表的规则，因为业务上都是按照机构纬度去查询，所以我们将机构id作为分库分表键。
  - 确保数据表有发号器生成的唯一键，有创建时间、更新时间和版本号。

- 数据同步
  - 主要是分为全量同步+增量同步

  - 开启binlog监听MQ（不消费）=〉全量数据同步新库 =〉开始消费binlogMQ =〉关闭binlog监听MQ =〉新老双写 =〉全量双向校验 =〉增量双向校验 =〉动态校验 =〉灰度切流  =〉 切流观察 =〉关闭双写双读

  - 历史数据全量同步：DBA协助帮忙处理历史数据hash后到新的库表中（也可以脚本select全量数据hash后插入新库表），在开始同步之前就要打开老库binlog消息订阅ROW模式，保存在MQ中，但是不消费，等到全量同步完成后新库开始消费消息（因为在复制过程中可能存在复制过的数据又发生了更新或删除动作，这样新库如果不处理这个操作，那么就会出现数据不一致的情况）
  - 实时数据同步：通过双写的方式实时保证新老库数据一致，当新库把binlog消息消费完后，就可以开启新老库实时双写，双写之前要停掉binlog的监听。先写老库，后写新库，如果老库写入失败，那请求返还失败，如果老库成功，新库失败那就记录失败日志，整体返回成功。这样确保老库的数据始终是准确的（如果对时延要求比较高的话，新库的写入可以异步完成）

- 数据校验

  - 全量双向校验：等到双写开始之后，我们可以基本认定新老库的数据是一致的，但也可能因为双写写入失败出现不一致的数据，而且我们的link关系是可以物理删除的，保险起见，我们进行新老库双向的校验检查，遍历老库中的数据，检查在新库中是否存在以及数据是否一致（因为可能新库创建失败）。遍历新库中的数据，检查在老库中是否存在以及数据是否一致（因为可能新库删除失败）。不一致的时候就记录类型和数据，方便后续捞取日志进行人工补偿。
  - 增量双向校验：定时任务每10min检查最近一小时更新数据是否一致，校验逻辑和全量双向校验一样。因为可能存在老库操作后，新库还没来得及更新，这种短暂不一致的情况，在此期间触发了定时任务的校验产生的告警，这个我们会根据告警id的出现次数来过滤这种情况，比如只去检查同一条数据告警次数统计大于3的记录
  - 动态校验：对灰度切读的机构，在查询的时候进行动态校验。同时查新老库的数据，比对新老库数据，如果不一致以老库数据为准，记录告警日志。
- 灰度切流

  - **机构打标灰度**，通过运营对机构打标的方式分批去对用户做读流量的迁移，打了标的读新库，没打标的读老库。如果通过白名单这种偏配置的对于需要配置的数据量太大不好处理，而且运营挑选的机构都是和平台配合度比较高，有问题的话影响面也会控制在一定范围内。
  - **确保随时能回切，**双写在彻底切换完成前都要开启，保证随时能够回切，切回的方式也很简单，机构去标就可以。



### 慢SQL处理

慢SQL的识别

慢SQL的处理



![image-20250609174423273](img/项目亮点/image-20250609174423273.png)

当前任务变更ID为：8704001，变更采用的临时表名是：tp_8704001_ogt_scm_shop_item_log,tp_8704001_del_scm_shop_item_log

DMS回放延迟 ：1 秒  回放延迟大于30秒，DMS会自动降低原表拷贝速率，如果此时延迟持续不断增加，说明原表的DML太高，无锁结构变更执行成功的几率较小，建议先暂停任务，并且在业务的低峰期重试任务。

状态说明：Job will scheduling in thread pool  状态说明：Copy data end. waiting cutover step...



切换表时锁表超时时间 ：2 秒    在切换表阶段，DMS需要同时给原表和临时表加锁禁写（加锁等待期间，也会阻塞表上的DML），然后实现两表的互换，该参数可以控制给表加锁的等待超时时间（DMS缺省为2秒）。时间越长，加锁成功率越高，但对业务DML影响时间越大。当表上有大事务、大查询导致频繁加锁失败时，可以酌情增加超时时间。



切换表失败时重试次数 ：5 次   在切换表阶段，当无法获取表的MDL锁或其它原因导致切表失败时，DMS缺省尝试3次切表过程，该参数可以控制累计重试次数。重试次数越多，切换表成功率越高，但同时短时间内频繁尝试切换表对业务的影响也会越大（获取MDL锁失败时，DMS间隔30秒重试一次）。





全量拷贝策略和大小 ：DMS动态调节(推荐)（当前值：60000）

在全量拷贝阶段，将原表分为N个小块逐个拷贝到临时表，DMS缺省根据数据库的性能动态调整每个小块的大小，兼顾对业务的影响和拷贝的速率，该参数可以更改拷贝策略和手动指定单次拷贝的大小。单次拷贝越大，全量拷贝的时间越短，但同时对业务的影响越大。

DMS根据数据库的性能，自动调整每次拷贝行数大小，单次拷贝锁表时间控制在1.5秒以内，兼顾速率和稳定性，推荐使用。



切换表完成后原表清理策略 ：直接删除无效原表(推荐) 在切换表完成后，DMS缺省直接删除原表（已无效），以尽快释放实例的空间，该参数可以控制切换表完成后原表清理方法。删除策略，可以在变更完成后自动释放实例空间；移动和保留策略，需要您后续手动删除无效的原表。



切换表的时间窗口 ： 

当原表全量拷贝完成并且增量追平后，DMS缺省立即开始切换表流程，如果此时正巧碰到业务高峰，可能会业务产生一些影响或者导致切表失败，该参数可以控制切换表的时间窗口，指定当满足切换表的条件并且在时间窗口以内时才进行切换，未在窗口内时则一直等待窗口。说明：SQL通过原生执行时，切表窗口无效。

增量回放数据校验比例 ：全量校验

在增量回放阶段，为保证数据一致性，DMS缺省会全量校验所有的binlog事件（校验对回放性能有轻微影响），该参数可以控制增量校验的比例。DMS推荐您校验全量数据，最大限度保证变更前后的数据一致性。如果回放延迟长期超过30秒，并且DMS已经回放了大量数据，可尝试降低校验比例提升回放性能（注意：回放延迟受多方面因素影响，该操作不一定有效）。







[ERROR] DMS-OnlineDDL Failed:无法获取到原表上的MDL锁，已尝试5次，请排查原表上的大事务、大查询，或到业务低峰期时重试任务



### MySQL架构

![image-20250615143057013](img/项目亮点/image-20250615143057013.png)

文件存储为.ibd文件

bufferPool 在磁盘和内存之间加一层进程纬度的缓存， 缓存的是16k的数据和索引页，读数据优先度读buffer pool。

文件系统中也有一个文件缓存，文件读取也会将文件加载到操作系统的文件缓存中，同样都是缓存，MySQL 设计进程纬度的缓存 bufferPool  是为了实现更多缓存淘汰策略，还能使用加锁等高级特性，因此有了 bufferPool 就不需要使用操作系统的文件缓存了，所以 bufferPool 通过直接IO模式，绕过操作系统的缓存机制，直接从磁盘读取数据。  

自适应Hash索引

ChangeBuffer，数据在更新的时候除了要更新主键索引外，还要维护对应字段的普通索引，可以将数据变更写入到 ChangeBuffer 中，然后等到对应的索引页要写入bufferPool的时候，再将对应更新应用到索引页中。通过这种方式来减少磁盘IO，提升性能。

UndoLog，为了保证数据的一致性，在事务回滚的时候需要对事务中执行成功的数据做回滚操作，这里就需要知道这条数据变更之前的版本， 所以在更新bufferPool中的数据页的时候，会根据旧数据生成对应的 UndoLog 记录。 存储在 bufferPool 中的特殊 UndoLog 内存页中。并随着bufferPool 的刷盘机制不定时写入到磁盘的 UndoLog 文件中。

RedoLog，在bufferPool的操作都是内存操作，如果内存操作只写了一半到磁盘中，数据库进程就崩了，事务还没来及的回滚，那么进程恢复的时候，需要保证事务的一致性。这就需要将事务中更新数据行的操作，都写入 RedoLogBuffer内存中，在事务提交的时候，进行RedoLog 刷盘，将数据固化到物理磁盘中。

数据库Server层，Server层本质上就是SQL语句和存储引擎的中间层。 一方面用于管理来自应用的网络连接，并提供 **分析器** 用于检查SQL语句的语法，提供 **优化器** 用于根据对应规则和索引生成对印的执行计划，以及提供 **执行器** 根据执行计划调用存储引擎层接口函数。Server层和存储引擎层共同构成一个完整的数据库。

binLog，Server层会将所有的变更操作，记录到磁盘上的binLog日志文件中，一旦误删表就可以通过 binLog 来恢复数据。

**语句执行流程**

客户端和Server建立网络连接，将SQL发送到Server层，然后分析器检查语法，优化器生成执行计划，执行调用存储引擎接口函数来执行。

读接口：判断 bufferPool 中是否存在所需的B+树数据页，如果存在则直接返回数据，不存在则从磁盘中读取相应的数据页加载到bufferPool中，再返回数据。

写接口：会将数据先写入 BufferPool 中，并生成对应的UndoLog 日志，以便在事务回滚时，能够恢复数据的原始状态。同时还会将写操作记录到 RedoLogBuffer中，这些RedoLogBuffer会周期的写入到磁盘 RedoLog 文件中，就算数据库奔溃，对于已提交的事务更新也不会丢失，对于辅助索引的更新操作，InnoDB 会将更新存在ChangeBuffer中，等到相关的索引页被读取到BufferPool时，再进行实际的更新操作，从而减少磁盘IO，提高写入性能。



**常见问题**

Mysql是什么？ 数据页是什么？ Mysql数据页为什么是16KB. B+树是什么？ 数据页和索引页是什么？ Buffer Pool是什么？ 自适应哈希索引是什么？ Change Buffer是什么？ Undo log是什么？ Redo log是什么？ InnoDB是什么？ Myisam是什么？ Mysql Server是什么？ Binlog是什么？ 有Redo log为什么还要有binlog？ Mysql连接器是什么 Mysql优化器是什么 Mysql执行器是什么 Mysql分析器是什么？ Mysql执行计划是什么？ 数据库查询流程 数据库更新流程

第一个为什么不能只用 redo log？

尽管 redo log 能保证崩溃恢复，但它有以下局限性：

redo log 只适用于 InnoDB 存储引擎，而 binlog 适用于所有存储引擎（如 MyISAM）。

redo log 是循环写的，日志空间固定，写满后会覆盖旧日志，无法用于长期数据恢复。

redo log 无法进行主从复制，MySQL 的主从同步机制依赖 binlog。

二、为什么不能只用 binlog？

虽然 binlog 记录了所有事务操作，但它也有局限性：

binlog 只是逻辑日志，记录的是SQL 语句或行级变更，但不保证事务的持久性。

binlog写入时机比 redo log 晚，如果数据库崩溃，binlog 可能还没来得及写入，导致数据丢失。

binlog只能用于恢复和同步，不提供崩溃恢复功能，因此不能替代 redo log。总结：为什么 MySQL 需要 redo log 和 binlog ？

redo log 解决的是崩溃恢复问题，保证事务的持久性。

binlog解决的是数据恢复、主从复制问题，记录所有数据变更，确保主从同步和时间点恢复（PITR）。

MySQL 事务提交的顺序是先写 redo log，再写 binlog，确保数据一致性。 

## MQ

### Kafka 架构 

kafka中也是 producer broker consumer 的概念。

kafka中 为了提升单个topic的性能，将单个topic拆分为多个partition，类比RocketMQ中的MessageQueue。

同时为了保证系统的扩展性，会将多个partition 分别部署到不同的broker上。

同时为了保证系统的可用性，为 Partition 增加了多个副本。

为了协调和管理 kafka 的数据消息，引入 zk 作为协调节点。

- ZK 在 kafka 架构中会和 broker通信，维护集群信息。当有新的 broker 加入集群后，其他的 broker 也会立马感知到，不过当新的broker加入后，它默认是没有数据的，需要通过kafka管理工具来重新分配分区和副本，重新分配分区涉及到数据迁移，需要谨慎操作，以免对集群性能造成影响。

![image-20250612110721861](img/项目亮点/image-20250612110721861.png)

### RocketMQ 架构

RocketMq 在 kafka 的基础上做了架构的简化和功能的增加。

![image-20250614001856446](img/项目亮点/image-20250614001856446.png)

### RocketMq 和Kafka 架构区别 

RocketMQ 设计是借鉴了Kafka的设计理念，并在架构上做了减法，在功能上做了加法。

**简化一：简化了分布式协调节点 zk**

Zookeeper 作为分布式服务协调节点，它不仅可以用于服务注册和发现，还可以用于分布式锁和配置管理等场景。 Kafka其实只用到了它的部分功能。对于消息队列本身来说可能太重了，所以 RockMQ 中直接将 Zookeeper去掉，换成Nameserver 用一种更轻量的方式管理消息队列中的集群信息。

> zk 在2.8版本后也支持移除 ZooKeeper，通过 broker 之间加入一致性算法 Raft 实现同样的效果。

**简化二：简化分区**

 Kafka 中会将一个topic 拆分成多个 Partition 分区，来提升消息消费的并发性能，RocketMQ 中将一个topic 也拆分成了多个MessageQueue 分区。Kafka 的Partition 中会存放完整的消息体，而 RocketMQ 中的 MessageQueue 中只存一些简要信息，比如消息的偏移量 offset。而消息的完整数据会存放在  CommitLog 中，通过 offset 可以快速定位到 CommitLog 上的某条消息。

因此在消费消息时，Kafka 只需要从 Partition 中读取完整消息消费，而 RocketMQ 需要先获取消息的偏移量offset，然后再根据偏移量到 CommitLog 中找到对应的完整消息。

**简化三：简化底层存储**

Kafka 的 Partition 分区在底层其实是由多个 segment 段来组成的， 每个 segment 都可以看作为是个小文件，将消息数据写入某个 Partition分区，其实本质是就是将数据写入到某个 segment 文件下。众所周知，顺序写磁盘的效率要远远高于随机写文件，所以单个的 segment 文件的写入是顺序写，但是由于kafka 中会有很多 topic，每个topic有多个 Partition 分区，然后每个 Partition 分区又对应多个 segment 文件。那么当同时写多个 topic 的时候，底层会触发对多个文件的读写，虽然每个文件内部都是顺序写，但是多个文件存放在磁盘的不同地方，原本的顺序写文件就可能劣化成随机写。于是写的性能就降低了。

RocketMQ 为了缓解同时写多个文件带来的随机写问题，它将单个 broker 下的多个topic 数据都统一写入到一个 文件 CommitLog 中，这个就消除了随机写多文件的问题，将所有写操作都变成了顺序写，大大的提升了 RocketMQ 在多 topic 场景下的写性能。

**简化四：简化备份模型**

Kafka 会将多个 Partition 分散到多个 broker 中，并为每个 Partition 配置副本，将 Partition 分为 leader 和 follower，也就是主从 Partition，主从 Partition 之间会建立数据同步，本质上就是同步 Partition 底下的 segment 文件数据。

RocketMQ 简化了底层存储，整个 broker 上的消息都存放在 CommitLog 中，所以 RocketMQ 直接同步 CommitLog 文件，以 broker 纬度来区分主从。保持高可用的同时也同时简化了数据备份模型。

**增加功能一：消息过滤**

RocketMQ 支持通过标签过滤消息的功能，而 Kafka 只能收到消息后在使用测根据自定义的消息类型来过滤。

**增加功能二：事务消息**

Kafka 的事务消息是保证多条消息发送的原子性，保证同时成功或者同时失败。而我们日常业务中更需要的是

业务代码和消息发送的一致性，RocketMQ 的事务半消息就能支持这样的场景。

**增加功能三：延时队列**

RocketMQ 通过延时队列支持延时消息的发送。

**增加功能四：死信队列**



### 事务消息原理 TODO

### 不丢消息 TODO

### 消费模式 TODO

### 顺序消息

例如商品的先改价再上架，如果不保证顺序性的和 他们

**生产方**

生产方线程通过实现**`MessageQueueSelector`** 接口，通过对分片键取模的方式，保证相同ID的商品变更消息会投放到同一个MessageQueue中。

**在业务层面上我们通过分布式锁的方式保证一个商品的变更消息是顺序的。**

**消息存储**

**Broker，会将所有消息按到达顺序追加到CommitLog文件，确保物理存储顺序与发送顺序一致。**

**消费方**

RocketMQ对提供了两种消费模式，一种是并发的消费方式 **MessageListenerConcurrently** ，和有序消费模式 **MessageListenerOrderly**，

顺序消息需要确保消费者注册的时候使用后者，每个消费者的消费端都是通过线程池的方式来消费消息的，只不过采用有序消费模式后，会分布式锁和本地锁来保证消息的有序消费。**确保同时只有一个消费者线程去消费一个消息队列中的消息。**

**即顺序消费模式使用3把锁来保证消费的顺序性：**

1.**broker端的分布式锁：**

- 在负载均衡的处理新分配队列的updateProcessQueueTableInRebalance方法，以及ConsumeMessageOrderlyService服务启动时的start方法中，都会尝试向broker申请当前消费者客户端分配到的messageQueue的分布式锁。
- broker端的分布式锁存储结构为ConcurrentMap<String/* group */, ConcurrentHashMap<MessageQueue, LockEntry>>，**该分布式锁保证同一个消费组consumerGroup下同一个消息队列messageQueue只会被分配给一个消费者客户端consumerClient。**
- 如果拿不到这个锁，则不会创建对应的ProcessQueue，同样也不会发送对应的消费请求。
- 获取到的broker端的分布式锁，在client端的表现形式为processQueue. locked属性为true，且该分布式锁在broker端默认60s过期，而在client端默认30s过期，因此ConsumeMessageOrderlyService#start会启动一个定时任务，每过20s向broker申请分布式锁，刷新过期时间。而负载均衡服务也是每20s进行一次负载均衡。

2.**messageQueue的本地synchronized锁：**

- 在执行消费任务的开头，便会获取该messageQueue的本地锁对象objLock，它是一个Object对象，然后通过synchronized实现锁定。
- 这个锁的锁对象存储在MessageQueueLock.mqLockTable属性中，结构为ConcurrentMap<MessageQueue, Object>，所以说，一个MessageQueue对应一个锁，不同的MessageQueue有不同的锁。
- 因为顺序消费也是通过线程池消费的，所以这个**synchronized锁用来当前这个消费者客户端中，保证同一时刻对于同一个队列只有一个消费线程去消费它。**

3.**ProcessQueue的本地consumeLock：**

- **消费线程具体消费某一条消息前要加的锁。**因为消费者会拉取一批消息处理。这个主要是因为负载均衡的场景，broker可能会把某个队列分配给新的消费者，那么当前持有这个队列的消费者需要进行释放，这个不是能随时中断的，需要等待处理完当前消息，提交消费位点后，完成consumeLock的解锁，才能取解分布式锁。

- ProcessQueue ，它是一个队列消费快照，消息拉取的时候，会将实际消息体、拉取相关的操作存放在其中。还有消费状态处理、offset提交等功能层面都是由ProcessQueue提供。

- **在获取到前两把锁后，每次在执行真正的消息消费的逻辑messageListener#consumeMessage之前**，会获取ProcessQueue的consumeLock，这把本地锁是一个ReentrantLock。**它的作用是防止消息被其他消费者客户端重复消费。**
- 因为在发生负载均衡的时候，消息队列可以会分配给新的消费者，那么当前客户端消费者需要对该队列进行释放，调用removeUnnecessaryMessageQueue方法请求broker端分布式锁的解锁。而在请求broker分布式锁解锁的时候，一个重要的操作就是首先尝试获取这个messageQueue对应的ProcessQueue的本地consumeLock。只有获取了这个锁，才能尝试请求broker端对该messageQueue的分布式锁解锁。
- 因为消费线程会拉取一批消息，在每次消费前都会加consumeLock，消费结束后释放consumeLock。如在消费过程中，消费了但还没提交消费位点，此时如果别的消费者客户端重新获取了当前消息队列，那么它也能拉到当前线程消费的消息，所以可能会导致消息重复消费。









## 常见中间件架构

### 配置中心 nacos  apollo  zk TODO

nacos 和 apollo 的namespace区别

## 商品推荐 

通过 数据分析 挖掘业务增长点，结合 NER 和 类目预测 对小B订单进行 商品推荐， 平均 提升有效GMV 26.7%。

**背景**：以往我们平台的成交流量都是来自于订单回采，所谓的订单回采是，小B供应商把我们供应链平台的商品铺货到面向用户的交易平台上，产生商品供货关系，然后当交易平台产生了对应商品的订单时，同时会在我们平台产生采购订单，完成履约链路。实现订单回采和一件代发。

可以看出订单回采的前提是，建立供货关系，但这个关系是小B手动去建立的。因为我们的供应链平台成立的比较晚，交易平台之前存在的大量商品是没有供货关系的，所以我们这个商品推荐其实就是去挖掘这一部分的潜在价值。

**action：** 

1.大数据报表统计分析，我们首先是通过大数据拉取过去一年网超交易平台的GMV，光浙江省一年的采购交易GMV就高达20多个亿，而我们供应链平台的交易渗透率不到1%，也就是说只有2000w的交易是和我们相关的，如果能把这个渗透率做到10%，那我们平台就有2个亿的GMV，抽佣2%也有400w的利润，这还只是一个省的，所以我们认为这个事情是值得去做的。

2.提升商品覆盖率，确保价格优势。我们先统计了热销商品前5000的热销商品覆盖率、以及热销品牌类目前100覆盖率，没有的话就去招商，谈价格。

3.建设判断同品的能力，简单来说就是根据两份异构的商品信息判断是否是相同的商品。

- 确定判断同品的指标：关键属性（品牌、类目、型号）和销售属性（不同类目的销售属性不同，如手机这个类目的销售属性有颜色、内存、容量）
- 建立用于商品推荐的索引：通过基础架构团队自建的NER来进行商品辅助分词，增强对于品类的识别，避免IK分词不准确的问题，例如有的品牌叫得力/Deli 有的是得力，通过NER来辅助识别这种情况。

4.应用场景落地，从工程测对这个项目在实际的应用场景下进行落地。比如应用我们通过监听交易平台的订单消息，然后去分析这些销售单在我们供应链平台有没有同款的商品

5.能力沉淀，商品推荐能力在其他场景的应用。

- IM即时聊天中的商品推荐，根据用户对话上下文信息，进行商品推荐。
- 询价业务中的商品推荐，根据用户输入信息智能匹配商品。

复盘：这个项目



## 商品标准化

- 品牌治理
- 类目治理
- 类目属性治理
- spu/cspu合并
- 一品一规 合并 一品多规
- 类目映射
- 类目属性映射







## 商品库存扣减优化

原始流程：

根据订单号加分布式锁，防止订单重复扣减 =〉校验对应单号是否存在扣减流水 =〉将库存查询至内存判断是否足额库存 =〉开启事务，事务内扣减库存(sql层面确保剩余库存大于0) 和 插入扣减流水和本地消息表，如果影响行数为0则更新失败，事务回滚

优化点：

**1.降低锁的粒度，将库存进行更细粒度的拆分**

将库存进行更细粒度的拆分，一条库存记录拆分成多条库存行，每个库存行绑定不同的仓库，不同的仓库对应的配送范围不同，在下单前需要去检查收获地址对应的仓库，获取到对应的库存行来进行扣减。这样就降低了锁的粒度。 

**2.减少锁的持有时间，调整SQL执行顺序**

事务中将插入流水的动作 放到 扣减动作 之前，因为扣减库存的时候会持有该记录的行锁，为了提高并发度，应该尽可能减少事务持有行锁的时间，而向流水表中插入数据，流水表本身数据量会比较大，而且插入还要维护相关索引信息，所以这个插入的耗时会越来越大。

**3.合并处理扣减请求，合并批处理**

合并批处理 借鉴OS刷盘机制，将多个用户对同一个商品库存行的扣减请求合并成一个内存队列，由定时任务去触发这个队列中的请求合并处理，将多次库存扣减请求合并成一个请求进行扣减，这样就把多次IO合并成了一次IO，当然这个定时任务触发的时间间隔非常短，200ms左右。 如果判断合并后的库存大于实际库存，那么会退化成优先从扣减数量大的请求来循环处理。

是否生成合并处理队列是根据当前商品库存行的并发度来判断的，通过内存中的计数器来统计滑动时间窗口内的单个商品的扣减次数决定商品的并发度。

**4.优化扣减失败处理逻辑**

优化前 扣减失败的时候：上游订单发送订单下单失败消息，判断有无流水，有流水释放库存插入释放流水，无流水直接返回消费成功。

库存扣减超时或者异步任务线程执行报错，导致上游的扣减请求拿到的结果都是扣减失败，这时候上游订单模块下单动作整体是失败的，这里边会涉及到分布式事务的回滚操作，上游会推送订单失败消息，我们接收到后会进行库存的释放。在释放前会去判断扣减流水是否存在。如果存在的话 返还库存并且插入释放库存的流水。

如果不存在的话，有两种情况，分别对应异步线程事务提交前和事务提交后，第一种情况的订单没有流水，所以也不用返还库存。第二种情况是，事务还没执行完上游接口就超时了，认为下单失败，发送回滚消息，但后续事务正常提交了，那就出现信息不一致的问题了，流水和订单就对不上。所以针对这种问题我们的处理方式是统一将将没有扣减流水的订单失败消息 进行消息转发重新消费，然后提交消息消费位点，防止阻塞其他顺序消息。

**5.优化更新库存时的缓存删除操作**

我们之前使用的时候旁路缓存模式，在更新的时候删除缓存，在查询的时候先查缓存，不存在的话查询数据库，并将查询结果缓存至redis。更新库存的时候也会去删除缓存，为了优化掉这个删除缓存的动作，对我们的缓存组件进行了调整，将手动删除的动作调整为监听数据库的binlog消息和监听领域事件消息进行缓存双删。



缺点：

本地消息表的方式依赖数据库，可能性能会成为瓶颈。可以考虑替换为事务消息。

不能通过横向扩容解决性能问题，因为加了机器后合并效果会变差。打到数据库的异步线程也会变多

链路长，复杂度较高，排查问题的成本和后续维护的成本会增加





## 考虑原因和职业规划 TODO

## 其他

**确保商品变更的消息一定要发送成功，**  本地消息表+顺序消息

商品管理和铺货信息的联动解耦



铺货应用监听商品变化，然后会创建

**联动不能丢失，通过本地消息表的方式解决**

为了确保商品变更的领域消息一定能够发送成功，我们引入了本地消息表，将商品的变更操作和领域消息的创建放在一个本地事务中提交。同时在提交事务后根据创建的本地消息记录id异步去发送消息并且修改消息发送状态，最终是由异步任务定时扫描消息表进行兜底。



联动不能出现覆盖丢失



A改了价格 B改了库存  那么



商品发品

商品铺货

标准库的建设

线上CPU100% 问题排查

系统流量激增100倍



监听商品价格变更消息  读取link关系   遍历link关系 判断是否售价亏本 来下架对应商品

监听商品价格变更消息  读取link关系   遍历link关系  zset 根据机构设置 涨价商品id，score 为过期时间

Redis Zremrangebyscore 命令用于移除有序集中，指定分数（score）区间内的所有成员。



商品架构

商品域 

- 商品基础信息域 

- 商品详情域

- 类目值对象

- 品牌值对象

- 商品属性域

- 商品标签域

- 商品服务承诺域

- 扩展字段域

- 商品SKU域

  - SKU价格域，细分为多个价格行，记录价格类型+ skuId
  - SKU库存域，细分为多个库存行，记录仓库id + 可用库存 + skuId

  



涨价 通知或者下架小B商品

小B 需要知道近7天涨价商品，因为多对多关系 读多写少 场景 所以把

电商订单场景需要消息通知下游，可以在事务提交后异步发送消息，考虑到消息可能会发送失败，所以还需要给下游提供反查的接口，查询时间区间内的订单接口，由消费端查缺补漏，这个方案优点：对于发送端实现比较简单，同时降低了事务的大小，提高了数据库的并发能力。但对于消费端而言，需要做额外的补偿工作。其次在使用场景上也有一定限制，例如商品变更就不太好反查，商品更新的消息会根据商品变更的领域事件类型，区分更细分的业务场景，例如价格变更、库存变更或者商品基础信息变更



发送失败不就是重试吗？重试的方案无非就那几个，简单重试、本地消息表重试、数据库消息表+(分布式)定时任务重试。至于使用哪种方案无非就是看系统的重要程度。 对于大部分非核心的业务来说，用简单重试或本地消息表重试就够了，Java有现成的本地消息表可以用，没的话，用简单重试也是可以的，然后再在消费端实现下定时任务对账就行了。 对于核心的大体量业务来说，用本地消息表是不够的，万一节点宕机，又启动不起来，那么依旧会存在数据丢失的风险，所以必须是数据库消息表+(分布式)定时任务来保证消息能发出去，但是不管是实施哪种方案，谁都是无法保证100%，所以消费端依旧还是得做好定时任务对账的工作。

价格同步和 高于售价冲突 

价格联动  库存联动 上下架联动 



```
乌柏:大B商品变更后 联动变更小B商品
卫易:牛啊
卫易:100%也太狂了吧
卫易:如何保证呢
乌柏:每次变更的大B商品 都会创建本地任务表  同时会创建任务明细
乌柏:然后走任务+重试的方式 
卫易:这个100%是统计的什么指标
乌柏:变更失败可能是业务上自身导致的失败 比如卖场的业务限制
卫易:这个100%是怎么统计的
乌柏:统计的是 大B商品变更后 同时联动变更多个小B商品  接口调用的指标
乌柏:不会说出现有丢系更新的情况
卫易:统计本地任务执行成功的数量？
乌柏:比如大B商品下架了  小B商品没联动跟着下架
乌柏:任务明细里的小B商品不一定能联动执行成功，但能保证每一条商品都会被调用对应的接口
乌柏:比如卖场把这个商品冻结了 我们就操作不了这个上下架状态了
乌柏:但是我们会调用对应的下架接口 然后记录失败原因
乌柏:有了这个失败原因 会预警+人工干预 
乌柏:保证了我们核心指标的一个触达率吧
乌柏:我不知道我这么理解的对不对
卫易:其实他会问几个指标
卫易:第一个是技术成功率
卫易:就刚才那个100%
卫易:这个指标的统计口径很关键
卫易:以及如何保证100%
乌柏:明白了
乌柏:那确实感觉技术上应该也做不到100%
卫易:100% 挺玄学的
卫易:还有就是   你既然是异步的 那么一定有吞吐
乌柏:任何一个地方出问题 就进行不下去
卫易:这个延迟是如何保证
乌柏:吞吐量吗
乌柏:我们对时延其实没有保证
卫易:B操作完b什么时候会更新
乌柏:只能说是 最终一定会更新到
卫易:那我今天改了价格或者上下架状态。  我第二天才会更新过去
卫易:那这一天下单的话不就资损了么
乌柏:这块的话 我们会去监控任务中心的状态 发现有任务长期堆积 未处理会告警 人工介入
乌柏:基本上联动更新都是2，3分钟内就能完成
乌柏:那你们这个是如何保证的
乌柏:以及激增的流量是如何处理
```







问的慢sql 整体的一个方案 

线上问题排查

业务指标和应用指标

还问了AI在哪些场景都应用

还问了DDD 的模型 

还有coderevicew

还有和外部对接遇到的一些问题





sync和ReentranLock 区别

dubbo的一个核心原理








