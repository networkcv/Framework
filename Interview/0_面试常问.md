## 自我介绍



## 职业规划

Q: 你的职业规划？
要点： 讲下你要成为怎么样的人

找准自身的定位和想要达成的目标，一年规划，三年规划

Q: 为此你做过什么努力？



### 讲下你的优缺点

### 项目

#### 项目简介

> 我简单介绍一下项目背景吧。 我们主数据商户只有一个工程。该工程既向外提供了原子查询服务的能力。又提供中台的管理能力。

#### 为什么要重写？

> 有几个原因吧。
>
> - 第一个原因是包含许多的废弃业务逻辑。无法响应业务的快速发展。比如说审核流。
> - 第二个原因是工程被许多团队维护过。代码风格极其不统一。
> - 第三个原因是接口设计不合理，存在许多相同功能的接口。
> - 第四个原因是部分接口性能出现问题。
>   综合下来 所以采用的是重写工程而不是重构。

#### 重写方案

- **准备阶段**

> 我说一下我们的重写方案吧。首先是与产品和测试对齐重写方针。
> 在准备阶段我们与产品首先确定商户的业务模型。比如确定销售商模型、营业部模型、公司模型等等。依照公司现有的业务逻辑。
> 依旧是准备阶段，开发会去收集各域依赖的接口。 我们当时的操作是直接拿到外域的代码权限。拉下来查看依赖的接口以及出入参。 然后形成表格之后与外域对接口。明确接口用途。这一步非常重要，它将直接影响你新接口的设计。

- **方案设计**

> 首先我们在工程中采用CQRS架构，将中台管理服务与对外原子查询服务分开，使用两个工程来实现。分别是phoenix和owl工程。两个工程都可以访问数据库。我们这么设计的目的是希望它们发布不会影响。 然后区别于管理服务调用原子服务，它没有分布式事务问题。
>
> 接口定义上，我们针对不同的业务实体定义了不同的接口。首先定义了一个基础属性的接口。该接口只包含基本信息，然后就是根据不同类型分别设计详细信息接口。然后就是关联关系接口。
> 并行开发。
> 然后就是外域切换。
> 系统下线。
> 数据模型变更。

- **实施**

> 开发阶段
> 对于OWL工程，我们采用DDD来落地。

- **为什么采用DDD？**

> 为了解决代码散乱，无法体现出业务与领域模型的这种情况。我们采用DDD，因为DDD可以直接在模型层了解到业务逻辑与领域行为。 然后就是DDD的模式可以解耦。 领域层和仓储层解耦，领域层无须关注具体存储哪张表。 让开发者对业务有更深层次的了解。 同时我认为它可以敏捷迭代。

- **你们的DDD是如何落地的？**

> 在工程中，我们使用CQRS架构，充血模型来落地。首先明确聚合。例如门店、仓库、公司等等是聚合根。 聚合根：具有全局标识 实体：只在聚合内有唯一标识。
> 在分层架构中，接口层调用应用服务层，应用服务层仅负责业务逻辑，比如说调用领域对象的行为。 例如现在有一个保存门店的方法。 在内存中构建出来一个门店对象，然后调用门店对象的行为来对内存中的领域对象进行修改。 同时行为会产生事件。 事件会存储在对象内部。当调用仓储层store方法提交事务之后，会调用事件发布将这些事件发布出去。 后续会有监听来实现 缓存清理和消息发送。

- **你们落地DDD的时候有没有遇到什么问题？是怎么解决的？**

> 第一个就是消息一致性问题。因为消息是由事件来驱动。 而消息又是业务中比较重要的一环。万一事务提交了但是消息因为各种原因发送失败了，那么对于下游业务就会存在问题。存在分布式一致性问题。
>
> **解决：**
> 对于业务消息，我们更改了方案，采用本地消息表，在事务中写表。然后异步线程会去发送这条消息。并将其置为已发送。 当时也考虑要引入其他团队开发的 分布式流程任务引擎来解决一致性问题，考虑到成本比较高，且我们编辑的情况不多，就采用了本地消息表。

- **讲一下你们的缓存方案吧**
- **你说你们进行了表结构优化，是做了哪方面的优化？**
- **你们有采集BinLog来同步ES的操作，对于消息乱序你们是如何解决的？**

经过后续跟进与查看源代码。 发现k8s环境下经典服务注册服务发现已经由K8S接管。询问基础架构组同学得知是因为ETCD服务宕机导致服务发现出现问题。

#### 分表问题

- **为什么分表？**

> 首先第一点是主表字段过多了。 有很多垃圾字段。
> 另外我们希望推进外域根据业务场景来辨别实际使用的业务实体类型。根据不同的实体用不同的表。还有就是需要去掉一些类型。

- **分表方案**

> 首先是写的问题。原先依赖主键Id。现在分表了，为了兼容性，不同实体Id全局唯一。因此我们采用了分段发号策略。在主表中找到目前已有的最大的Id，加一位，然后根据不同的实体采用不同的号段。基于数据量不大的情况下，不需要引入分布式发号服务。降低复杂度。
> 同时也可以根据号段来区分新老Id与类型。

#### **服务器指标**

1. 线上QPS最高是到5000
2. RT时间 是99%200ms之内  90%50ms
3. 线上GC回收基本保持在20ms以内

## 线上CPU100%的问题排查

某天早上，我们发现业务方数据查询报错，上游也发现各种接口超时。查看机器负载发现有一台机器CPU负载已经满了。根据GRPC默认的负载均衡策略是轮询请求，不可能每一次都有问题。但异常几乎必现。 我们查看线上日志。发现线上全部都是Redis连接获取超时。 连接获取超时肯定是所有的连接都被占满了无法释放。 无法释放的原因可能是Redis问题也可能是线程被挂起无法释放连接。 查看Redis发现指标正常，除了连接数飙升以外。 推断是CPU资源问题导致获取连接超时。 切换到其他的POD节点发现并没有这个异常。 大致可以推断是负载均衡出现了问题，导致所有流量都打到了一台机器上。

## 轻量级缓存组件

https://blog.csdn.net/youbl/article/details/113052502

1. 基于注解，不侵入代码，使用Spring AOP实现，轻量级，相比Spring 提供的注解缓存，可扩展性更高一些。

2. kernelCache缓存的删除是基于binlog的，基础架构会将bin log解析发送至消息队列，我们监听消息去处理删缓存，这里也可以做一些延时双删的操作，来保证db缓存的一致性。

3. 还有一些都是默认的Redis缓存实现不支持，需要去实现相关扩展接口的。

   - 默认的RedisCacheManager是使用JDK的序列化，性能差；我们自己的缓存组件也就是kernelCache，是可配置序列化方式，默认gson。

   - 默认的是无法配置不同的缓存过期时间；kernelcache可以根据缓存枚举中的过期时间时间来差异化配置。

   - 默认是同步写缓存的，而kernelCache是异步线程池写缓存。

     

## **保证分布式事务最终一致性的流程引擎**

通过注解的方式将需要进行rpc调用的步骤包装起来，可以由外部系统进行步骤的编排和远程调用。外部系统中可以控制调用的时间以及获取调用结果，还支持步骤失败的重试，以及报警。

底层运用到了netty springbootstart rpc调用相关技术。

流程引擎接入

- 调用方引入依赖包，依赖包里会使用SPI注册一个引擎的服务

- 将需要保证最终一致性的rpc调用包装成执行步骤（processor）。每个processor都有自己的唯一标识

- 将原来多次rpc调用的地方，进行引擎点火，点火需要传入序列化后的入参和指定唯一的流程id（一个流程相当于原来的本地事务）

- 去引擎的管理后台对流程进行步骤配置，步骤之间可以串行也可以并行。

  

## 技术面试官问题

1. 技术栈相关
2. 服务运行在云上吗，云平台 云原生
3. 业务体量，服务器的一些指标 QPS  RT 
4. 此次面试的评价

## TL问题

1. 团队的人员，在做的项目，未来规划，业务体量
2. 有过有幸入职前，我需要准备或者学习的内容
3. 您觉得我还有哪些不足的地方

## HR问题

1. 公司有没有一些系统性的培训，可以更快的融入公司
2. 团队的绩效评估
3. 薪资结构

