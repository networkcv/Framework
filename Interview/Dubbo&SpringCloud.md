如果聊分布式这块的技术，围绕**Dubbo来拷问**的，但是呢，现在其实非常流行的是**Spring Cloud，Dubbo和Spring Cloud以及阿里系的一些技术**，现在正在融合，**Spring Cloud Alibaba，只不过现在用的公司暂时还没那么多而已**

作为合格的工程师，行业里主流的**分布式服务技术栈**，**Dubbo**和**Spring Cloud**两种，有的公司他是用**Dubbo**的，不用**Spring Cloud**的，有的公司是用**Spring Cloud**的，不用**Dubbo**的，他们是代表了两种主流技术栈

Java工程师，Dubbo和Spring Cloud起码是基本原理，都有一定的了解

**大白话 + 现场画图**

上网看一些博客资料，或者是买一些Spring Cloud的书，可能没考虑过一个事儿，第一篇必须是用非常通俗的语言，把一个系统如果用Spring Cloud来做分布式架构的话，那么他需要用到Spring Cloud哪些组件，为什么

跟着书或者博客，直接上手开始搭建demo，开始做起来了

**分别用Dubbo和Spring Cloud做两个最基本的Demo工程**，用电商背景来搭建几个服务

比如说，现在我们有一个电商系统

用户现在需要下单购买一些东西这样子，订单系统、库存系统、仓储系统、积分系统

不太可能说用单块的架构，电商系统你想支撑多少用户量？10万注册用户，日活1000用户来你这里来购买？

百万级用户，十万级日活，单块系统就不太合适了，背后有几十个人的团队在协作开发，此时单块系统是绝对不合适的

梳理和明确一个概念：电商系统，拆分为了多个子系统，一次下订单的请求需要多个子系统协作完成，每个子系统都完成一部分的功能，多个子系统分别完成自己负责的事情，最终这个请求就处理完毕

我们不会让每个视频太长，按照我们大纲来讲，说是60讲，粗略的大纲，其实最终会拆分成可能上百讲，Spring Cloud架构原理，我们就要分为上下两讲来说 ![Spring Cloud核心架构原理](img/1-Dubbo&SpringCloud/SpringCloud-core-architecture.png)

### Spring Cloud

#### Eureka：服务注册中心  油瑞克

服务注册：服务启动后会去注册中心注册自己的接口调用，

服务发现：各个服务会不停的去注册中心拉取注册表到本地，以感知到其他的服务接口

#### Feign：服务调用	费恩

执行具体的服务调用

#### Ribbon：负载均衡	瑞本恩

对发现的服务进行负载均衡算法，从提供一个服务的多个机器中选出一个来，交由Feign进行调用

#### Zuul/Spring Cloud Gatway:网关

网关负责对后端所有接口的路由，它可以通过服务注册中心感知到各个服务的地址，前端在调用后端接口的时候，不需要知道其他的地址，只需要和网关打交道即可。相当于将网关后面的系统作为了一个黑盒

这么多的系统，电商系统包含了20个子系统，每个子系统有20个核心接口，一共电商系统有400个接口，这么多的接口，直接对外暴露，前后端分离的架构，难道你让前端的同学必须记住你的20个系统的部署的机器，他们去做负载均衡，记住400个接口

网关还可以做很多功能，如：

**灰度发布**：只更新部分机器的代码，让网关放一些流量过去进行验证，没有问题后再对所有机器进行更新

**统一限流**：比如架构系统只能承受1w的并发，超过1w的并发请求在网关这里就会被干掉

**统一授权认证**：对请求进行权限认证

**统一熔断**、**统一降级**、**统一缓存**、





**Hystrix**、**链路追踪**、**stream**、很多组件，Hystrix这块东西，其实是会放在高可用的环节去说的，并不是说一个普通系统刚开始就必须得用的，没有用好的话，反而会出问题，**Hystrix线路熔断的框架**，必须得设计对应的一整套的限流方案、熔断方案、资源隔离、降级机制，配合降级机制来做

## 为什么要进行系统拆分？如何进行系统拆分？拆分以后不用dubbo可以吗？

方便项目的开发，测试，部署和迭代，解决代码冲突
拆分的话，分多轮拆，可以按层拆分，也可以按模块拆分 云童康养
不使用dubbo，还可以使用springcloud，不用rpc，通过http协议也是可以实现系统间通信的，不过代价比较高

## dubbo工作原理

- 第一层：service层,接口层，服务提供者和消费者提供 ，需要手动实现
- 第二层：config层，配置层，任何一个框架，都需要提供配置文件，来配置框架
- 第三层：proxy层，代理层，无论是consumer还是provider，dubbo都会生成代理，代理之间进行网络通信
- 第四层：registry层，注册层，provider注册自己作为一个服务，consumer就可以去注册中心找要调用的服务
- 第五层：cluster层，集群层，provider可以部署在多台机器上，多个provider就组成了一个集群
- 第六层：monitor层，监控层，consumer调用provider，调用了多少次，统计信息监控
- 第七层：protocol层，协议层，负责具体的provider和consumer之间调用接口的网络通信
- 第八层：exchange层，信息交换层，封装请求响应模式，同步转异步
- 第九层：transport层，网络传输层，抽象mina和netty为统一接口
- 第十层：serialize层,数据序列化层

## 工作流程

![01_dubbo的工作原理](img/1-Dubbo&SpringCloud/01_dubbo的工作原理.png)


## 注册中心挂了可以继续通信吗？

可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。


## dubbo支持哪些通信协议和序列化协议？

- dubbo协议  
  dubbo://192.168.0.1:20188  
  默认使用的是dubbo协议，单一长连接，NIO异步通信，基于 hessian 作为序列化协议  
  适用的场景是：传输的数据量很小，100kb以内，consumer远远多于provider 并发量很高  

- rmi协议  
  使用java二进制序列化，多个短连接，适合consumer和provider数量差不多，适用于文件的传输

- hessian协议  
  使用hessian序列化，多个短连接，适用于provider多于consumer，适用于文件传输

- http协议  
  使用jsonxulxh

- webservice  
  使用SOAP文本序列化

## dubbo支持哪些负载均衡、高可用（集群容错）以及动态代理生成的策略？

负载均衡策略：  

- random loadbalance  
  随机调用实现负载均衡，可以根据不同provider的机器环境设置权重，权重越大分配的流量越高

- roundrobin loadbalance  
  默认会均匀地将流量分发到各个机器上，如果机器性能不同，性能差的机器会造成负载过高，需要调整权重  

- leastactive loadbalance    
  dubbo自动感知，某个机器的性能越差，那么接收的请求越少  

- consistanthash loadbalance  
  一致性的hash算法，如果需要一类请求都到一个节点上，使用这个一致性hash策略  



dubbo集群容错策略：  

- failover cluster模式  
  失败自动切换，自动重试其他机器，常见于读操作   

- failfast cluster模式   
  一次调用失败就立即失败，常见于写操作  

- failsafe cluster模式  
  出现异常时忽略掉，常用于不重要的接口调用，比如记录日志  

- failback cluster模式  
  失败了后台自动记录请求，然后定时重发，比较适合于写消息队列  

- forking cluster模式  
  并行调用多个provicer，只要一个成功就理解返回  

- broadcast cluster模式  
  逐个调用所有的cluster  



dubbo动态代理策略：  
默认使用javassist动态字节码生成，创建代理类  
可以通过SPI扩展机制配置自己的动态代理策略

## dubbo的SPI机制？基于SPI机制对dubbo进行扩展

SPI（service provider interface），如果一个接口有3个实现类，那么系统运行的时候对这个接口到底选择哪个实现类。这就需要SPI了，需要根据指定的配置或是默认的配置，找到对应的实现类加载进来，然后用这个实现类的实例对象  
经典的思想体现：jdbc  java定义了一套jdbc接口，但是没有提供jdbc的实现类  
使用不同的数据库，可以通过导入不同的jdbc驱动来实现  
dubbo也使用了SPI思想，不过没有使用JDK的SPI机制，而是自己实现的一套SPI机制  


## 基于dubbo进行服务治理、服务降级及超时重试

### 服务治理：

- 调用链路自动生成  
  记录各个服务之间的调用，将服务之间的依赖关系和调用链路以图片的形式来呈现
- 服务访问压力以及时长统计
  自动统计各个接口和服务之间的调用次数已经访问延时，而且要分为两个级别  
  一是接口粒度，就是每个服务的每个接口每天被调用多少次，请求延时分别是多少  
  二是从源头开始，一个完整的请求链路后，全天全链路走了多少次，延时分别是多少
- 其它  
  服务分层（避免循环依赖）   
  调用链路失败监控和报警  
  服务鉴权  
  每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）  

### 服务降级：  

比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。

```xml
<beans>
    <dubbo:application name="dubbo-consumer"  />
    <dubbo:registry address="zookeeper://127.0.0.1:2181" />
    <dubbo:reference id="fooService" interface="com.test.service.FooService"  timeout="10000" check="false" mock="return null">
    </dubbo:reference>
</beans>
```

mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+Mock” 后缀。然后在 Mock 类里实现自己的降级逻辑。

```java
public class HelloServiceMock implements HelloService {
    public void sayHello() {
        // 降级逻辑
    }
}
```

### 超时重试：  

所谓超时重试，就是 consumer 调用 provider 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。  
配置如下：

```xml
<dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" imeout="2000"/>  
```

timeout：一般设置为 200ms，我们认为不能超过 200ms 还没返回。  
retries：设置 retries，一般是在读请求的时候，比如你要查询个数据，你可以设置个 retries，如果第一次没读到，报错，重试指定的次数，尝试再次读取。

## 分布式系统接口的幂等性

这个不是技术问题，具体需要结合业务来保证幂等性，针对核心业务保证幂等性  
其实保证幂等性主要是三点：

- 对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一个订单 id 最多支付一次，对吧。
- 每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中记录个状态啥的，比如支付之前记录一条这个订单的支付流水。
- 每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水，orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。

## 分布式的接口调用的顺序性

从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，因为一旦引入顺序性保障，比如使用分布式锁，会导致系统复杂度上升，而且会带来效率低下，热点数据压力过大等问题。

下面我给个我们用过的方案吧，简单来说，首先你得用 dubbo 的一致性 hash 负载均衡策略，将比如某一个订单 id 对应的请求都给分发到某个机器上去，接着就是在那个机器上，因为可能还是多线程并发执行的，你可能得立即将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性。

![02_分布式的接口调用的顺序性.png](img/1-Dubbo&SpringCloud/02_分布式的接口调用的顺序性.png)

但是这样引发的后续问题就很多，比如说要是某个订单对应的请求特别多，造成某台机器成热点怎么办？解决这些问题又要开启后续一连串的复杂技术方案......曾经这类问题弄的我们头疼不已，所以，还是建议什么呢？

最好是比如说刚才那种，一个订单的插入和删除操作，能不能合并成一个操作，就是一个删除，或者是其它什么，避免这种问题的产生。

### 分布式锁方案  

100%保证请求的处理顺序，请求到接入服务后，给每个请求封装一个请求的orderId=1和seq=(1/2/3)  
使用zookeeper分布式锁，根据seq的先后来决定请求的处理先后顺序

## 自己如何设计一个类似于dubbo的rpc框架

其实问到你这问题，你起码不能认怂，因为是知识的扫盲，那我不可能给你深入讲解什么 kafka 源码剖析，dubbo 源码剖析，何况我就算讲了，你要真的消化理解和吸收，起码个把月以后了。

所以我给大家一个建议，遇到这类问题，起码从你了解的类似框架的原理入手，自己说说参照 dubbo 的原理，你来设计一下，举个例子，dubbo 不是有那么多分层么？而且每个分层是干啥的，你大概是不是知道？那就按照这个思路大致说一下吧，起码你不能懵逼，要比那些上来就懵，啥也说不出来的人要好一些。

举个栗子，我给大家说个最简单的回答思路：

- 上来你的服务就得去注册中心注册吧，你是不是得有个注册中心，保留各个服务的信息，可以用 zookeeper 来做，对吧。
- 然后你的消费者需要去注册中心拿对应的服务信息吧，对吧，而且每个服务可能会存在于多台机器上。
- 接着你就该发起一次请求了，咋发起？当然是基于动态代理了，你面向接口获取到一个动态代理，这个动态代理就是接口在本地的一个代理，然后这个代理会找到服务对应的机器地址。
- 然后找哪个机器发送请求？那肯定得有个负载均衡算法了，比如最简单的可以随机轮询是不是。
- 接着找到一台机器，就可以跟它发送请求了，第一个问题咋发送？你可以说用 netty 了，nio 方式；第二个问题发送啥格式数据？你可以说用 hessian 序列化协议了，或者是别的，对吧。然后请求过去了。
- 服务器那边一样的，需要针对你自己的服务生成一个动态代理，监听某个网络端口了，然后代理你本地的服务代码。接收到请求的时候，就调用对应的服务代码，对吧。

这就是一个最最基本的 rpc 框架的思路，先不说你有多牛逼的技术功底，哪怕这个最简单的思路你先给出来行不行？

# Dubbo源码

聊**分布式**这块，**Dubbo相关的原理**，**Spring Cloud相关的原理**，有的面试官可能会这样问，你有没有看过**Dubbo或者Spring Cloud的源码呢**？**技术广度**、**技术深度**、**项目经验**、**系统设计**、**基本功**

平时看你简历主要是用一些技术来开发一些系统，就会问问你了，对于一些你平时常用的技术，有没有关注过底层的原理，或者是看过源码，你要是说，90%的人，一般都会在这个时候支支吾吾的说

源码看过一点点，但是没怎么看过

在我们面试训练营里，能给你来分析源码吗？不太现实的，任何一个开源项目，**源码**少则几万行，多则几十万行，**Hadoop、Spark**，**面试训练营**，几讲的时间来讲透任何一个**开源项目**的**源码**，不现实

看源码技巧是有，但是，需要**技术功底**

就是说提炼一些**Dubbo、Spring Cloud**相关的一些底层的运行的原理，给大家来用大白话+现场画图的方式，说清楚，你就可以结合我们视频讲解的内容，去现场画图给面试官画一画一些技术底层的运行的一些原理



## 分布式系统

拆分为了多个子系统之后，各个系统之间如何通过Spring Cloud服务框架来进行调用，Dubbo框架来进行调用

[![Dubbo核心架构原理](img/1-Dubbo&SpringCloud/dubbo-framework-principle.png)](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/images/dubbo-framework-principle.png) 提供接口

![/dev-guide/images/dubbo-framework.jpg](img/1-Dubbo&SpringCloud/dubbo-framework.jpg)

服务注册中心：

\###消费者

#### 动态代理：Proxy

#### 负载均衡：Cluster，负载均衡，故障转移

#### 注册中心：Registry

#### 通信协议：Protocol，filter机制，http、rmi、dubbo等协议

#### http、rmi、dubbo

比如说，我现在其实想要调用的是，DemoService里的sayHello接口

你的请求用什么样的方式来组织发送过去呢？以一个什么样的格式来发送你的请求？

http，/demoService/sayHello?name=leo rmi，另外一种样子 dubbo，另外一种样子，interface=demoService|method=sayHello|params=name:leo

信息交换：Exchange，Request和Response

对于你的协议的格式组织好的请求数据，需要进行一个封装，Request

##### 网络通信：Transport，netty、mina

##### 序列化：封装好的请求如何序列化成二进制数组，通过netty/mina发送出去

提供者

#### 网络通信：Transport，基于netty/mina实现的Server

#### 信息交换：Exchange，Response

#### 通信协议：Protocol，filter机制

#### 动态代理：Proxy



这个面试题还是挺常见的，在面试突击第一季里，基本上带了一下，当时但是没有细讲，是因为当时面试突击第一季里对服务框架的原理没有做一个相对深入一点点的分析，当时主要就是讲了一些最基本的概念

人家并不是要你手撸一个**RPC框架**，资料，现场手撸一个**RPC框架**，撸的特别的简单，人家也不是要你手撸，也不是说让你进来了以后就是让你来研发RPC框架的

系统设计的问题，就是让你站在系统设计的角度，来考虑一下，到底如果要设计一个RPC框架，你会如何来考虑

动态代理：比如消费者和提供者，其实都是需要一个实现某个接口的动态代理的，RPC框架的一切的逻辑细节，都是在这个动态代理中实现的，动态代理里面的代码逻辑就是你的RPC框架核心的逻辑

JDK提供了API，去创建针对某个接口的动态代理

调用动态代理对象的方法之后，此时就应该先干一个事情，通过Cluster层的一些组件，服务注册中心，是用什么技术来进行实现呢？往简单了说，服务注册中心也可以是你自己手撸一个，也不难

自己手撸一个，服务去注册，其他服务去拉取注册表进行发现

**ZooKeeper**，稍微自己上网百度搜索一下，**ZooKeeper**入门使用教程，基本概念和原理，还有基本的使用，了解一下

**Cluster层**，从本地缓存的服务注册表里获取到要调用的服务的机器列表

**负载均衡**，**面试突击第一季**里，我们分析过**Dubbo的负载均衡策略**，此时你就可以把那些策略说一说，我要设计多少种策略，从服务的机器列表中采用负载均衡算法从里面选择出来一台机器

选择好了机器，知道了对方的端口号，而且知道你的请求调用，调用哪个Interface的哪个方法，把这些信息交给协议层

把数据组织一下，**协议**，**序列化机制**，**底层用什么网络通信框架**，比如**netty，mina**现在用的比较少，序列化和反序列化有没有概念，**Java基础概念，一个复杂的请求数据序列化成二进制的字节数组**

**反序列化就是从字节数组变成请求数据结构**

按照那个协议的规范对请求数据进行组织，不同的协议，组织出来的数据看起来是不一样的

## **netty基本的原理**

解析完毕了之后，就知道，应该调用自己本地哪个Interface的实现类的哪个方法

![Dubbo底层通信原理](img/1-Dubbo&SpringCloud/dubbo-rock-bottom.png)

# SpringCloud

问你**Dubbo底层架构原理**是一样的，不求你说能看过**Spring Cloud的源码**，单单就是说搞明白他的一些底层架构原理，也是不错的

[![Eureka服务注册中心的原理](img/1-Dubbo&SpringCloud/springCloud-study-theory.png)](https://github.com/shishan100/Java-Interview-Advanced/blob/master/docs/distributed-system/images/springCloud-study-theory.png) **Eureka、Ribbon、Feign、Zuul**

**Eureka**

主要作为 **服务注册与发现** 和 **心跳检测**

 就是优化并发冲突

如果你基于**Spring Cloud**对外发布一个接口，实际上就是支持**http协议**的，对外发布的就是一个最最普通的**Spring MVC的http接口**

**feign**，他是对一个接口打了一个注解，他一定会针对这个注解标注的接口生成动态代理，然后你针对feign的动态代理去调用他的方法的时候，此时会在底层生成http协议格式的请求，/order/create?productId=1

底层的话，使用HTTP通信的框架组件，**HttpClient**，**先得使用Ribbon去从本地的Eureka注册表的缓存里获取出来对方机器的列表，然后进行负载均衡，选择一台机器出来，接着针对那台机器发送Http请求过去即可**

配置一下不同的请求路径和服务的对应关系，你的请求到了网关，他直接查找到匹配的服务，然后就直接把请求转发给那个服务的某台机器，**Ribbon从Eureka本地的缓存列表里获取一台机器，负载均衡，把请求直接用HTTP通信框架发送到指定机器上去**

底层架构原理是类似的



# SpringCloud 和 Dubbo对比

**Dubbo，RPC的性能比HTTP的性能更好，并发能力更强，经过深度优化的RPC服务框架，性能和并发能力是更好一些**

很多中小型公司而言，其实稍微好一点的性能，**Dubbo一次请求10ms，Spring Cloud耗费20ms**，对很多中小型公司而言，性能、并发，并不是最主要的因素

**Spring Cloud这套架构原理，走HTTP接口和HTTP请求，就足够满足性能和并发的需要了，没必要使用高度优化的RPC服务框架**

Dubbo之前的一个定位，就是一个单纯的服务框架而已，不提供任何其他的功能，配合的网关还得选择其他的一些技术

**Spring Cloud**，中小型公司用的特别多，老系统从**Dubbo迁移到Spring Cloud**，新系统都是用**Spring Cloud来进行开发，全家桶，主打的是微服务架构里，组件齐全，功能齐全。网关直接提供了，分布式配置中心，授权认证，服务调用链路追踪，Hystrix可以做服务的资源隔离、熔断降级、服务请求QPS监控、契约测试、消息中间件封装、ZK封装**

剩是剩在功能齐全，中小型公司开箱即用，直接满足系统的开发需求

**Spring Cloud**原来支持的一些技术慢慢的未来会演变为，跟阿里技术体系进行融合，**Spring Cloud Alibaba**，阿里技术会融入**Spring Cloud**里面去



# 服务在生产环境部署

中小型的系统，拆分为10~~20个服务，2、3台机器就足够了，把服务的上线、故障以及发现优化到极致

服务上线，注册表多级缓存同步1秒，注册表拉取频率降低为1秒 服务心跳，1秒上报1次 故障发现，1秒钟检查一次1心跳，如果发现2秒内服务没上报心跳，认为故障了

服务注册中心都没任何压力，最多就是每秒钟几十次请求而已

服务注册中部署个2台机器，每台机器就是4核8G，高可用冗余，任何一台机器死掉，不会影响系统的运行

服务注册中心这样的一个处理逻辑，4核8G的机器，每秒钟轻松抗几百请求，上千请求也是可以的

通常来说，如果每秒钟的并发在1000以内的话，很少部署的，每个服务部署2台机器，每台机器4核8G，每台机器每秒抗个几百请求，一点问题都没有，别搞出来一个请求过来，查数据库SQL写的太烂了，一条SQL要跑3秒钟

大部分的系统，高峰期每秒几百请求，低峰期每秒几十请求，甚至几个请求

网关系统，4核8G的机器，一台机器抗每秒几百请求，部署3~4台机器，保证可以网关系统每台机器的压力比较小，进一步保证网关系统可靠性

数据库，MySQL，建议16核32G，物理机最佳，32核64G，最多抗个每秒钟几千请求问题不大，平时抗个每秒钟几十或者几百请求，三四千请求，但是只不过此时会导致MySQL机器的负载很高，CPU使用率很高，磁盘IO负载很高，网络负载很高



# QPS 请求量、每秒请求量，成功次数，失败次数

很常问，很多人回来跟我说，老师，我不知道我们系统每秒钟请求有多少，每天请求量有多大，我都没任何的概念，因为系统开发好直接部署，根本不管这些东西，有没有什么比较好的工具可以看到服务的访问量，qps

每个服务每天多少请求量，高峰期每秒钟多少请求量，你完全可以在代码里，稍微加一些metrics的代码，如果你看过很多的开源项目的话，开源的分布式系统，eureka、hadoop、spark、hbase、kafka，metrics机制

任何一个开源系统都需要对自己运行过程中各种请求量、每秒的请求量、成功次数、失败次数，在内存里直接做一些计数，他会给你开放一些端口号，比如http端口号，你只要请求他这个端口号，他就会把这些metrics统计返回给你

在你负责的核心服务里，核心接口，开发一个简单的metric统计机制，AtomicLong，原子性，并发下数据统计准确，不会错误，每个接口被调用的时候，一个是可以对每个接口每分钟都做一个Metric统计

对每个接口每天的请求使用一个AtomicLong做一个计数，统计出来每天的请求次数

计算一下每个接口从请求到执行完毕，需要耗费多长时间，算一下每个接口平均的请求延时，TP99，TP95，TP90，TP50，TP99，99%的请求耗费的时间在100ms以内，但是1%的请求可能耗费的时间在100ms以上

**TP99 = 100ms** **TP95 = 50ms，95%的请求耗费的时间多在50ms以内，但是5%的请求耗费的时间在50ms以上**

平均响应延时

你可以计算出来这个接口平均响应延时，把每次调用的耗时跟历史总耗时加起来，除以当前的请求次数，不就是最新的接口响应平均延时

你完全可以通过log4j，logback，日志组件，把每分钟每个接口被访问的次数直接打印到日志文件里去，除以60，不就知道高峰期每秒钟系统被访问的次数了吗，每天每个接口访问的总次数打印到日志里去

压测工具，百度一下：java压测工具，开源的可以用的，模拟出来同时有多少用户发起多少请求，每秒发起1000请求能抗住吗？每秒钟发起2000请求能抗住吗？

假设你的系统每秒钟最多抗800请求，如果你的压测工具每秒发起了1000个请求，此时他会发现最多只有800个请求同时可以被处理，剩余200个请求需要进行排队被阻塞住了，告诉你，你的这个系统每秒钟最多抗800个请求